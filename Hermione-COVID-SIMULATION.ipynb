{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a43748c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# norm: self-quarantine and vaccine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "906bf94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mesa import Agent, Model\n",
    "from mesa.time import RandomActivation, BaseScheduler\n",
    "from mesa.space import MultiGrid\n",
    "from mesa.datacollection import DataCollector\n",
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "import csv\n",
    "from statistics import mean\n",
    "from pathlib import Path\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from collections import deque\n",
    "import time\n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16c51d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Simulation Parameters ###\n",
    "\n",
    "# === to change\n",
    "file_name = 'sanctioning'#hermione noe\n",
    "\n",
    "# general\n",
    "num_train_iterations = 50\n",
    "num_eval_iterations = 20\n",
    "num_steps = 2000\n",
    "num_agents = 100\n",
    "agent_per_home = 1\n",
    "\n",
    "startingState = 0.3\n",
    "vaccine_multiplier = 0.5\n",
    "home_recovery_multiplier = 2\n",
    "\n",
    "num_grocery_stores = 1\n",
    "num_parks = 1\n",
    "\n",
    "FQ_frames = 5\n",
    "\n",
    "# locations\n",
    "HOME = 0\n",
    "PARK = 1\n",
    "GROCERY_STORE = 2\n",
    "HOSPITAL = 3\n",
    "\n",
    "# emotion\n",
    "POSITIVE = 1\n",
    "NEUTRAL = 0\n",
    "NEGATIVE = -1\n",
    "\n",
    "vaccine_last = num_steps#10\n",
    "\n",
    "location_space = [HOME, PARK, GROCERY_STORE, HOSPITAL]\n",
    "\n",
    "NOT_INFECTED = 0\n",
    "INFECTED_A = 1\n",
    "INFECTED_S = 2\n",
    "CRITICAL = 3\n",
    "DECEASED = 4\n",
    "\n",
    "health_space = [NOT_INFECTED, INFECTED_A, INFECTED_S, CRITICAL, DECEASED]\n",
    "\n",
    "# real evolve_prob = [0.5, 0.18, 0.0054, 0.1, 0]\n",
    "# evolve_prob = [0.5, 0.5, 0.1, 0.3, 0]\n",
    "evolve_prob = [0.8, 0.36, 0.01, 0.2, 0]\n",
    "# recover_prob = [0, 0.4, 0.3, 0.2, 0]\n",
    "recover_prob = [0, 0.2, 0.1, 0.05, 0]\n",
    "\n",
    "#oberve prob\n",
    "N_prob = [0.8,0,0.9,1]\n",
    "A_prob = [0.5,0,1,1]\n",
    "S_prob = [0.3,0,0.9,1]\n",
    "C_prob = [0.1,0,0.4,1]\n",
    "\n",
    "# === to change\n",
    "#sanction prob\n",
    "hard_sanctioning_prob = 0.38#0.2\n",
    "message_sanctioning_prob = 0.6\n",
    "emotion_sanctioning_prob = 0.85#1\n",
    "sanction_prob_w_health = [0,0,0.5,0.8]\n",
    "\n",
    "# baseline 2        : prob for sanction 20%\n",
    "# baseline 3 emotion: prob for sanction 20% emotion 80%\n",
    "# baseline 4 message: prob for sanction 20% message(belief reward) 40% \n",
    "# enfo              : prob for sanction 20% emotion(belief reward) 80%\n",
    "# test1             : prob for sanction 20% emotion(belief reward) 65%\n",
    "# test2             : prob for sanction 16% emotion(belief reward) 80%\n",
    "\n",
    "\n",
    "# desire/intention\n",
    "stay_home = 0\n",
    "go_outdoors = 1\n",
    "go_shopping = 2\n",
    "\n",
    "intention_space = [stay_home, go_outdoors, go_shopping]\n",
    "\n",
    "# actions\n",
    "MOVE_HOME = 0\n",
    "MOVE_PARK = 1\n",
    "MOVE_STORE = 2\n",
    "MOVE_HOSPITAL = 3\n",
    "\n",
    "action_space = [MOVE_HOME, MOVE_PARK, MOVE_STORE, MOVE_HOSPITAL]\n",
    "sanction_space = ['location', 'health']\n",
    "\n",
    "env_path = ''\n",
    "tfboard_dir = env_path + 'tensorboard/' + file_name + '/'\n",
    "checkpoint_path = env_path + 'models/' + file_name + '/'\n",
    "figure_path = env_path + 'figures/' + file_name + '/'\n",
    "logs_path = env_path + 'logs/' + file_name + '/'\n",
    "\n",
    "lr = 0.001#0.00025\n",
    "gamma = 0.9\n",
    "epsilon_greedy = 0.9\n",
    "epsilon_min = 0.1\n",
    "\n",
    "# === to change\n",
    "agent_type_primitive = 1\n",
    "agent_type_sanctioning = 2\n",
    "agent_type_message = 3\n",
    "agent_type_noe = 4\n",
    "agent_type_emotion = 5\n",
    "\n",
    "agent_type = agent_type_sanctioning\n",
    "\n",
    "SELF = 0\n",
    "OTHERS = 1\n",
    "\n",
    "# norms\n",
    "norm = {\n",
    "            \"type\": \"prohibition\",\n",
    "            \"subject\": SELF,\n",
    "            \"object\": OTHERS,\n",
    "            \"antecedent\": {\n",
    "                \"location\": [PARK, GROCERY_STORE, HOSPITAL],\n",
    "                \"attribute\": \"perceived_health\",\n",
    "                \"value\": [INFECTED_S, CRITICAL]\n",
    "            }, \n",
    "            \"consequent\": {\n",
    "                \"emotion\": -0.3, \n",
    "                \"message\": -0.5,\n",
    "                # emotion\n",
    "                \"hard_sanction\": -1\n",
    "            }\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73984878",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RL(object):\n",
    "    def __init__(self, actions):\n",
    "        self.actions = actions\n",
    "        self.lr = lr\n",
    "        self.gamma = gamma\n",
    "        self.epsilon_greedy = epsilon_greedy\n",
    "        \n",
    "        self.q_table = pd.DataFrame(columns = self.actions, dtype = np.float64)\n",
    "    \n",
    "    def instantialize(self):\n",
    "        return\n",
    "    \n",
    "    def check_state_exist(self, state):\n",
    "        if state not in self.q_table.index:\n",
    "            self.q_table.loc[state] = pd.Series(\n",
    "                [0] * len(self.actions),\n",
    "                index = self.q_table.columns\n",
    "                )\n",
    "\n",
    "    def action_select(self, state, n_iteration, evaluate):\n",
    "        self.check_state_exist(state)\n",
    "        if evaluate or (np.random.uniform() > 0.9 * (num_train_iterations - n_iteration) / num_train_iterations):\n",
    "            actions= self.q_table.loc[state, :]\n",
    "            action = np.random.choice(actions[actions == np.max(actions)].index)\n",
    "        else:\n",
    "            action = np.random.choice(action_space)\n",
    "        return action\n",
    "    \n",
    "    def getQ(self, state, action):\n",
    "        return self.q_table((state, action), 0.0)\n",
    "\n",
    "class QLearningTable(RL):\n",
    "    def __init__(self, actions):\n",
    "        super(QLearningTable, self).__init__(actions)\n",
    "    \n",
    "    def learn(self, s, a, r, s_):\n",
    "        self.check_state_exist(s_)\n",
    "        q_predict = self.q_table.loc[s, a]\n",
    "        q_target = r + self.gamma * self.q_table.loc[s_, :].max()\n",
    "        # check NaN\n",
    "        q_target = 0 if np.isnan(q_target) else q_target\n",
    "        self.q_table.loc[s, a] += self.lr * (q_target - q_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "185be85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "RL_brain = QLearningTable(actions = list(range(len(action_space))))\n",
    "Sanction_brain = QLearningTable(actions = list(range(len(sanction_space))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a64e9c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HumanAgent(Agent):\n",
    "    \"\"\"The actor in the simulation.\"\"\"\n",
    "    def __init__(self, unique_id, model, evaluate):\n",
    "        super().__init__(unique_id, model)\n",
    "        \n",
    "        self.homeId = unique_id // agent_per_home\n",
    "        self.health = NOT_INFECTED\n",
    "        self.perceived_health = NOT_INFECTED\n",
    "        \n",
    "        self.x = HOME\n",
    "        self.y = unique_id // agent_per_home\n",
    "        \n",
    "        self.infected_times = 0\n",
    "        \n",
    "        self.external_reward = 0\n",
    "        \n",
    "        self.FQ_frames = 0\n",
    "        \n",
    "        self.last_action = None\n",
    "        \n",
    "        self.vaccinated = False\n",
    "        self.vaccine_last = 0\n",
    "        self.intention = 0\n",
    "        self.self_directed_emotion = 0\n",
    "        self.other_directed_emotion = 0\n",
    "        \n",
    "        self.evaluate = evaluate\n",
    "        self.reward = 0\n",
    "        \n",
    "        self.reset_death = False\n",
    "    \n",
    "    def initialize(self):\n",
    "        self.state = self.get_state(0)\n",
    "    \n",
    "    def step(self):\n",
    "        \n",
    "        if self.health != DECEASED:\n",
    "            self.act()\n",
    "        self.updateHealth()\n",
    "    \n",
    "    def get_state(self, env_emotion = None):\n",
    "        loc_x, loc_y = self.pos\n",
    "        return [loc_x, loc_y, self.health, self.intention, self.FQ_frames, self.vaccinated, self.vaccine_last]\n",
    "    # maybe after action\n",
    "    def updateHealth(self):\n",
    "        if self.health == DECEASED:\n",
    "           return\n",
    "\n",
    "        x,y = self.pos\n",
    "        \n",
    "        if self.health in (INFECTED_A, INFECTED_S, CRITICAL):\n",
    "            p = self.random.uniform(0, 1)\n",
    "            ev_prob = evolve_prob[self.health] * (vaccine_multiplier if self.vaccinated else 1)\n",
    "            rec_prob = recover_prob[self.health] * (home_recovery_multiplier if x == HOME else 1)\n",
    "            if p < ev_prob:\n",
    "                self.health += 1\n",
    "            elif p < ev_prob + rec_prob:\n",
    "                self.health = NOT_INFECTED\n",
    "            \n",
    "            if self.health == NOT_INFECTED:\n",
    "                if p < N_prob[NOT_INFECTED]:\n",
    "                    self.perceived_health = NOT_INFECTED\n",
    "                elif p < N_prob[INFECTED_S]:\n",
    "                    self.perceived_health = INFECTED_S\n",
    "                elif p < N_prob[CRITICAL]:\n",
    "                    self.perceived_health = CRITICAL\n",
    "            elif self.health == INFECTED_A:\n",
    "                if p < A_prob[NOT_INFECTED]:\n",
    "                    self.perceived_health = NOT_INFECTED\n",
    "                elif p < A_prob[INFECTED_S]:\n",
    "                    self.perceived_health = INFECTED_S\n",
    "                elif p < A_prob[CRITICAL]:\n",
    "                    self.perceived_health = CRITICAL        \n",
    "            elif self.health == INFECTED_S:\n",
    "                if p < S_prob[NOT_INFECTED]:\n",
    "                    self.perceived_health = NOT_INFECTED\n",
    "                elif p < S_prob[INFECTED_S]:\n",
    "                    self.perceived_health = INFECTED_S\n",
    "                elif p < S_prob[CRITICAL]:\n",
    "                    self.perceived_health = CRITICAL\n",
    "            elif self.health == CRITICAL:\n",
    "                if p < C_prob[NOT_INFECTED]:\n",
    "                    self.perceived_health = NOT_INFECTED\n",
    "                elif p < C_prob[INFECTED_S]:\n",
    "                    self.perceived_health = INFECTED_S\n",
    "                elif p < C_prob[CRITICAL]:\n",
    "                    self.perceived_health = CRITICAL\n",
    "            elif self.health == DECEASED:\n",
    "                self.model.deceasedCount += 1\n",
    "                self.perceived_health = DECEASED\n",
    "                self.reset_death = True\n",
    "                return\n",
    "            \n",
    "            \n",
    "                    \n",
    "        if self.FQ_frames > 0:\n",
    "            self.FQ_frames -= 1\n",
    "        return\n",
    "    \n",
    "    def perceive(self):\n",
    "        x, y = self.pos\n",
    "        return self.model.perceive(x, y, self.unique_id)\n",
    "    \n",
    "    def infect(self, close_contact):\n",
    "        p = self.random.uniform(0, 1)\n",
    "        if self.health == NOT_INFECTED:\n",
    "            if close_contact:\n",
    "                self.health += 1\n",
    "                self.infected_times += 1\n",
    "            else:\n",
    "                if p < (evolve_prob[NOT_INFECTED] * vaccine_multiplier) and self.vaccinated:\n",
    "                    self.health += 1\n",
    "                    self.infected_times += 1\n",
    "                elif p < evolve_prob[NOT_INFECTED] and not self.vaccinated:\n",
    "                    self.health += 1\n",
    "                    self.infected_times += 1\n",
    "    \n",
    "    def act(self):\n",
    "        x, y = self.pos\n",
    "        \n",
    "        # action selection\n",
    "        self.intention = np.random.choice(intention_space)\n",
    "        \n",
    "        if self.FQ_frames > 0:\n",
    "            self.last_action = MOVE_HOME\n",
    "            if x != HOME:\n",
    "                self.model.grid.move_agent(self, (HOME, self.unique_id // agent_per_home))\n",
    "                self.x = HOME\n",
    "                self.y = self.unique_id // agent_per_home\n",
    "        else:\n",
    "            action = RL_brain.action_select(str(self.state), self.model.iteration, self.evaluate)\n",
    "            # run action\n",
    "            if action == MOVE_HOME:\n",
    "                self.model.grid.move_agent(self, (HOME, self.unique_id // agent_per_home))\n",
    "                self.x = HOME\n",
    "                self.y = self.unique_id // agent_per_home\n",
    "            elif action == MOVE_STORE:\n",
    "                rd = self.random.randint(0, num_grocery_stores - 1)\n",
    "                self.model.grid.move_agent(self, (GROCERY_STORE, rd))\n",
    "                self.x = GROCERY_STORE\n",
    "                self.y = rd\n",
    "            elif action == MOVE_PARK:\n",
    "                rd = self.random.randint(0, num_parks - 1)\n",
    "                self.model.grid.move_agent(self, (PARK, self.random.randint(0, num_parks - 1)))\n",
    "                self.x = PARK\n",
    "                self.y = rd\n",
    "            elif action == MOVE_HOSPITAL:\n",
    "                self.model.grid.move_agent(self, (HOSPITAL, 0))\n",
    "                self.x = HOSPITAL\n",
    "                self.y = 0\n",
    "                self.vaccinated = True\n",
    "                self.vaccine_last = vaccine_last\n",
    " \n",
    "            self.last_action = action\n",
    "\n",
    "        if agent_type in (agent_type_noe, agent_type_emotion):\n",
    "            self.elicit_emotion(self.intention)\n",
    "    \n",
    "    # elicit self-directed emotion\n",
    "    def elicit_emotion(self, intention):\n",
    "        x, y = self.pos\n",
    "        \n",
    "        # farced to stay at home\n",
    "        if x == HOME and self.FQ_frames > 0:\n",
    "            self.self_directed_emotion = -1\n",
    "        else:\n",
    "            emotion = (1 if x == intention else -1)\n",
    "            # ===\n",
    "            if x != HOME and self.health > 0:\n",
    "                emotion += -1\n",
    "            elif x == HOME and self.health > 0:\n",
    "                emotion += 1\n",
    "            \n",
    "            #===\n",
    "    \n",
    "            if emotion == 2: emotion = 1\n",
    "            if emotion == -2: emotion = -1\n",
    "            self.self_directed_emotion = emotion\n",
    "        \n",
    "\n",
    "    def learn(self, force = False):\n",
    "        x, y = self.pos\n",
    "        pre_state = self.state\n",
    "        \n",
    "        self.reward = 0\n",
    "        env_emotion = 0\n",
    "        \n",
    "        if agent_type in (agent_type_noe, agent_type_emotion):\n",
    "            self.state = self.get_state(0)\n",
    "        else:\n",
    "            self.state = self.get_state(0)\n",
    "        \n",
    "        if self.health == DECEASED and not self.reset_death:\n",
    "            if self.x != HOME or self.x != -1:\n",
    "                self.model.grid.move_agent(self, (HOME, self.unique_id // agent_per_home))\n",
    "                self.x = HOME\n",
    "                self.y = self.unique_id // agent_per_home\n",
    "            self.reward, self.FQ_frames = 0, 0\n",
    "            self.self_directed_emotion, self.other_directed_emotion = 0, 0\n",
    "            self.intention, self.last_action, self.x, self.y = -1, -1, -1, -1\n",
    "            return\n",
    "        \n",
    "        reward = -2 if self.health == DECEASED else 0\n",
    "        \n",
    "        if self.FQ_frames > 0:\n",
    "            reward -= 1\n",
    "        \n",
    "        reward += 1 if self.intention == x else -1\n",
    "        \n",
    "        if agent_type in (agent_type_noe, agent_type_emotion):\n",
    "            reward += (self.self_directed_emotion + self.other_directed_emotion)\n",
    "        \n",
    "        reward += self.external_reward\n",
    "        \n",
    "        self.reward = reward\n",
    "        \n",
    "        self.reset_death = False\n",
    "        self.external_reward = 0\n",
    "        \n",
    "        if self.evaluate:\n",
    "            return\n",
    "        \n",
    "        RL_brain.learn(str(pre_state), self.last_action, reward, str(self.state))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8fe18820",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimulationModel(Model):\n",
    "    \"\"\"The model runs the simulation.\"\"\"\n",
    "    def __init__(self, N, iteration, evaluate):\n",
    "        self.num_agents = N\n",
    "        self.random.seed(1)\n",
    "        self.evaluate = evaluate\n",
    "        \n",
    "        self.grid = MultiGrid(5, num_agents // agent_per_home, False)\n",
    "        self.schedule = RandomActivation(self)\n",
    "        self.iteration = iteration\n",
    "        \n",
    "        self.deceasedCount = 0\n",
    "        \n",
    "        self.datacollector = DataCollector(\n",
    "            model_reporters={\n",
    "#                 \"infected\": self.compute_infected,\n",
    "#                             \"deceased\": self.compute_deceased,\n",
    "#                              \"compliance\": self.compute_compliance,\n",
    "#                              \"violation\": self.compute_violation,\n",
    "#                              \"ratio\": self.compute_compliance_rate,\n",
    "#                             \"home\": self.compute_QC,\n",
    "#                             \"home_quarantine\": self.compute_FQ,\n",
    "#                             \"vaccinated\": self.compute_vaccinated\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        self.reset()\n",
    "    \n",
    "    def reset(self):\n",
    "        if self.schedule.get_agent_count() > 0:\n",
    "            for agent in self.schedule.agents:\n",
    "                self.schedule.remove(agent)\n",
    "        # load agents\n",
    "        for i in range(self.num_agents):\n",
    "            a = HumanAgent(i, self, self.evaluate)\n",
    "            self.schedule.add(a)\n",
    "            self.grid.place_agent(a, (HOME, 0))\n",
    "        \n",
    "        for a in self.random.sample(self.schedule.agents, int(startingState * self.num_agents)):\n",
    "            a.health = INFECTED_A\n",
    "            a.infected_times += 1\n",
    "        \n",
    "        for agent in self.schedule.agents:\n",
    "            agent.initialize()\n",
    "        \n",
    "        self.deceased_count = 0\n",
    "        self.violation_count = 0\n",
    "        self.compliance_count = 0\n",
    "        self.cumulative_deceased = 0\n",
    "        self.cumulative_violation = 0\n",
    "        self.cumulative_compliance = 0\n",
    "    \n",
    "    def run_norms(self):\n",
    "        emotion_saction_set, message_sanction_set, hard_saction_set = set(), set(), set()\n",
    "        # Home\n",
    "        for y in range(num_agents // agent_per_home):\n",
    "            agents = self.grid.get_cell_list_contents([(HOME,y)])\n",
    "            comply_agents = [agent for agent in agents if agent.health != DECEASED and agent.perceived_health != NOT_INFECTED and agent.FQ_frames == 0 ]\n",
    "            for agent in comply_agents:\n",
    "                agent.external_reward -= norm.get(\"consequent\").get(\"hard_sanction\")\n",
    "                if agent_type in (agent_type_emotion, agent_type_noe):\n",
    "                    agent.other_directed_emotion = 1\n",
    "        # Park\n",
    "        if PARK in norm.get(\"antecedent\").get(\"location\"):\n",
    "            for y in range(num_parks):\n",
    "                agents = self.grid.get_cell_list_contents([(PARK,y)])\n",
    "                agents = [agent for agent in agents if agent.health != DECEASED ]\n",
    "                violate_agents = [agent for agent in agents if getattr(agent, norm.get(\"antecedent\").get(\"attribute\")) in norm.get(\"antecedent\").get(\"value\") ]\n",
    "                \n",
    "                if len(agents) - len(violate_agents) > 0:\n",
    "                    for agent in violate_agents:\n",
    "                        sanctioners = [sanctioner for sanctioner in agents if sanctioner.health == NOT_INFECTED and sanctioner.unique_id != agent.unique_id]    \n",
    "\n",
    "                        hard_sanction, sanction = False, False\n",
    "                        p = self.random.uniform(0, 1)\n",
    "                        if p < sanction_prob_w_health[agent.perceived_health]:\n",
    "                            p = self.random.uniform(0, 1)\n",
    "                            if p < hard_sanctioning_prob:\n",
    "                                agent.FQ_frames = FQ_frames\n",
    "                                hard_sanction = True\n",
    "                            \n",
    "                            elif agent_type == agent_type_message:\n",
    "                                if p < message_sanctioning_prob:\n",
    "                                    sanction = True\n",
    "                                    agent.external_reward += norm.get(\"consequent\").get(\"message\")\n",
    "                            elif agent_type in (agent_type_emotion, agent_type_noe):\n",
    "                                if p < emotion_sanctioning_prob:\n",
    "                                    sanction = True\n",
    "                                    if agent_type == agent_type_emotion:\n",
    "                                        agent.external_reward += norm.get(\"consequent\").get(\"emotion\")\n",
    "                                    agent.other_directed_emotion = -1\n",
    "\n",
    "                        if agent_type in (agent_type_emotion, agent_type_noe) and sanction:\n",
    "                            for sanctioner in sanctioners:\n",
    "                                if sanctioner.unique_id not in emotion_saction_set:\n",
    "                                    emotion_saction_set.add(sanctioner.unique_id)\n",
    "                                    sanctioner.other_directed_emotion = 0\n",
    "\n",
    "        # Grocery\n",
    "        if GROCERY_STORE in norm.get(\"antecedent\").get(\"location\"):\n",
    "            for y in range(num_grocery_stores):\n",
    "                agents = self.grid.get_cell_list_contents([(GROCERY_STORE,y)])\n",
    "                agents = [agent for agent in agents if agent.health != DECEASED ]\n",
    "                violate_agents = [agent for agent in agents if getattr(agent, norm.get(\"antecedent\").get(\"attribute\")) in norm.get(\"antecedent\").get(\"value\") ]\n",
    "                \n",
    "                if len(agents) - len(violate_agents) > 0:\n",
    "                    for agent in violate_agents:\n",
    "                        sanctioners = [sanctioner for sanctioner in agents if sanctioner.health == NOT_INFECTED and sanctioner.unique_id != agent.unique_id]    \n",
    "                        \n",
    "                        hard_sanction, sanction = False, False\n",
    "                        p = self.random.uniform(0, 1)\n",
    "                        if p < sanction_prob_w_health[agent.perceived_health]:\n",
    "                            p = self.random.uniform(0, 1)\n",
    "                            if p < hard_sanctioning_prob:\n",
    "                                agent.FQ_frames = FQ_frames\n",
    "                                hard_sanction = True\n",
    "                            \n",
    "                            elif agent_type == agent_type_message:\n",
    "                                if p < message_sanctioning_prob:\n",
    "                                    sanction = True\n",
    "                                    agent.external_reward += norm.get(\"consequent\").get(\"message\")\n",
    "                            elif agent_type in (agent_type_emotion, agent_type_noe):\n",
    "                                if p < emotion_sanctioning_prob:\n",
    "                                    sanction = True\n",
    "                                    if agent_type == agent_type_emotion:\n",
    "                                        agent.external_reward += norm.get(\"consequent\").get(\"emotion\")\n",
    "                                    agent.other_directed_emotion = -1\n",
    "\n",
    "                        if agent_type in (agent_type_emotion, agent_type_noe) and sanction:\n",
    "                            for sanctioner in sanctioners:\n",
    "                                if sanctioner.unique_id not in emotion_saction_set:\n",
    "                                    emotion_saction_set.add(sanctioner.unique_id)\n",
    "                                    sanctioner.other_directed_emotion = 0\n",
    "\n",
    "            \n",
    "        if HOSPITAL in norm.get(\"antecedent\").get(\"location\"):\n",
    "            agents = self.grid.get_cell_list_contents([(HOSPITAL,0)])\n",
    "            agents = [agent for agent in agents if agent.health != DECEASED ]\n",
    "            violate_agents = [agent for agent in agents if getattr(agent, norm.get(\"antecedent\").get(\"attribute\")) in norm.get(\"antecedent\").get(\"value\") ]\n",
    "            \n",
    "            if len(agents) - len(violate_agents) > 0:\n",
    "                for agent in violate_agents:\n",
    "                    sanctioners = [sanctioner for sanctioner in agents if sanctioner.health == NOT_INFECTED and sanctioner.unique_id != agent.unique_id]\n",
    "                    \n",
    "                    hard_sanction, sanction = False, False\n",
    "                    p = self.random.uniform(0, 1)\n",
    "                    if p < sanction_prob_w_health[agent.perceived_health]:\n",
    "                        p = self.random.uniform(0, 1)\n",
    "                        if p < hard_sanctioning_prob:\n",
    "                            agent.FQ_frames = FQ_frames\n",
    "                            hard_sanction = True\n",
    "                            \n",
    "                        elif agent_type == agent_type_message:\n",
    "                            if p < message_sanctioning_prob:\n",
    "                                sanction = True\n",
    "                                agent.external_reward += norm.get(\"consequent\").get(\"message\")\n",
    "                        elif agent_type in (agent_type_emotion, agent_type_noe):\n",
    "                            if p < emotion_sanctioning_prob:\n",
    "                                sanction = True\n",
    "                                if agent_type == agent_type_emotion:\n",
    "                                    agent.external_reward += norm.get(\"consequent\").get(\"emotion\")\n",
    "                                agent.other_directed_emotion = -1\n",
    "\n",
    "#                     if hard_sanction and agent.health == NOT_INFECTED:\n",
    "#                         for sanctioner in sanctioners:\n",
    "#                             if sanctioner.unique_id not in hard_saction_set:\n",
    "#                                 hard_saction_set.add(sanctioner.unique_id)\n",
    "#                                 sanctioner.other_directed_emotion = -1\n",
    "#                                 sanctioner.external_reward += norm.get(\"consequent\").get(\"hard_sanction\")\n",
    "#                                 if agent.health == NOT_INFECTED:\n",
    "#                                     sanctioner.external_reward += norm.get(\"consequent\").get(\"hard_sanction\")\n",
    "                    \n",
    "                    # less penalty for wrong accuse of message; no penalty for emotion\n",
    "#                     if agent_type == agent_type_message and sanction:\n",
    "#                         for sanctioner in sanctioners:\n",
    "#                             if sanctioner.unique_id not in message_sanction_set:\n",
    "#                                 message_sanction_set.add(sanctioner.unique_id)\n",
    "#                                 sanctioner.other_directed_emotion = -1\n",
    "#                                 sanctioner.external_reward += norm.get(\"consequent\").get(\"message\")\n",
    "#                                 if agent.health == NOT_INFECTED:\n",
    "#                                     sanctioner.external_reward += norm.get(\"consequent\").get(\"message\")\n",
    "                \n",
    "                    if agent_type in (agent_type_emotion, agent_type_noe) and sanction:\n",
    "                        for sanctioner in sanctioners:\n",
    "                            if sanctioner.unique_id not in emotion_saction_set:\n",
    "                                emotion_saction_set.add(sanctioner.unique_id)\n",
    "                                sanctioner.other_directed_emotion = 0\n",
    "\n",
    "    def perceive(self, x, y, agent_id):\n",
    "        agents = self.grid.get_cell_list_contents([(x, y)])\n",
    "        emotions = [agent.other_directed_emotion for agent in agents if agent.unique_id != agent_id]\n",
    "        return sum(emotions)/len(emotions) if len(emotions) > 0 else 0\n",
    "    \n",
    "    def learn(self):\n",
    "        for i in range(self.num_agents):\n",
    "            agent = self.schedule._agents[i]\n",
    "            agent.learn()\n",
    "    \n",
    "    def compute_infected(self):\n",
    "        infectedAgents = [agent for agent in self.schedule.agents if agent.health in (INFECTED_A, INFECTED_S, CRITICAL) ]\n",
    "        return len(infectedAgents)\n",
    "    \n",
    "    def compute_deceased(self):\n",
    "        deceasedAgents = [agent for agent in self.schedule.agents if agent.health == DECEASED ]\n",
    "        return len(deceasedAgents)\n",
    "    \n",
    "    def compute_compliance(self):\n",
    "        agents = [agent for agent in self.schedule.agents if agent.last_action == MOVE_HOME and agent.health not in (NOT_INFECTED, DECEASED) ]\n",
    "        return len(agents)\n",
    "    \n",
    "    def compute_violation(self):\n",
    "        agents = [agent for agent in self.schedule.agents if agent.last_action != MOVE_HOME and agent.health not in (NOT_INFECTED, DECEASED) ]\n",
    "        return len(agents)\n",
    "    \n",
    "    def compute_compliance_rate(self):\n",
    "        comp = self.compute_compliance()\n",
    "        vio = self.compute_violation()\n",
    "        return comp / (comp + vio) if comp + vio > 0 else 0\n",
    "    \n",
    "    def compute_vaccinated(self):\n",
    "        agents = [agent for agent in self.schedule.agents if agent.vaccinated and agent.health != DECEASED ]\n",
    "        return len(agents)\n",
    "    \n",
    "    def compute_QC(self):\n",
    "        count = 0\n",
    "        for y in range(num_agents // agent_per_home):\n",
    "            agents = self.grid.get_cell_list_contents([(HOME,y)])\n",
    "            count += len(agents)\n",
    "        return count\n",
    "    \n",
    "    def compute_FQ(self):\n",
    "        count = 0\n",
    "        for y in range(num_agents // agent_per_home):\n",
    "            agents = self.grid.get_cell_list_contents([(HOME,y)])\n",
    "            agents = [agent for agent in agents if agent.FQ_frames > 1]\n",
    "            count += len(agents)\n",
    "        return count\n",
    "    \n",
    "    def step(self):\n",
    "        self.schedule.step()\n",
    "        if agent_type != agent_type_primitive:\n",
    "            self.run_norms()\n",
    "        self.identifyAgentsAndUpdateSpread()\n",
    "        self.learn()\n",
    "        self.write_csv()\n",
    "        self.datacollector.collect(self)\n",
    "        self.decay_emotion()\n",
    "    \n",
    "    def decay_emotion(self):\n",
    "        for i in range(self.num_agents):\n",
    "            agent = self.schedule._agents[i]\n",
    "            agent.other_directed_emotion = 0\n",
    "            agent.self_directed_emotion = 0\n",
    "\n",
    "    def write_csv(self):\n",
    "        if self.iteration <= num_train_iterations:\n",
    "            return\n",
    "        \n",
    "        with open(logs_path + file_name + '_agent.csv', 'a', newline = '') as agent_file:\n",
    "            writer = csv.writer(agent_file, delimiter = ',')\n",
    "            for i in range(self.num_agents):\n",
    "                agent = self.schedule._agents[i]\n",
    "                if agent_type in (agent_type_primitive, agent_type_sanctioning):\n",
    "                    writer.writerow([self.iteration, self.schedule.steps, agent.unique_id, agent.health, agent.infected_times, agent.reward, agent.FQ_frames, agent.vaccinated, agent.vaccine_last, agent.intention, agent.last_action, agent.x, agent.y, agent.self_directed_emotion, agent.other_directed_emotion])\n",
    "                elif agent_type == agent_type_message:\n",
    "                    writer.writerow([self.iteration, self.schedule.steps, agent.unique_id, agent.health, agent.infected_times, agent.reward, agent.FQ_frames, agent.vaccinated, agent.vaccine_last, agent.intention, agent.last_action, agent.x, agent.y, agent.self_directed_emotion, agent.other_directed_emotion])\n",
    "                elif agent_type == agent_type_noe:\n",
    "                    writer.writerow([self.iteration, self.schedule.steps, agent.unique_id, agent.health, agent.infected_times, agent.reward, agent.FQ_frames, agent.vaccinated, agent.vaccine_last, agent.intention, agent.last_action, agent.x, agent.y, agent.self_directed_emotion, agent.other_directed_emotion])\n",
    "                else:\n",
    "                    writer.writerow([self.iteration, self.schedule.steps, agent.unique_id, agent.health, agent.infected_times, agent.reward, agent.FQ_frames, agent.vaccinated, agent.vaccine_last, agent.intention, agent.last_action, agent.x, agent.y, agent.self_directed_emotion, agent.other_directed_emotion])\n",
    "        agent_file.close()\n",
    "    \n",
    "    def identifyAgentsAndUpdateSpread(self):\n",
    "        # Park\n",
    "        for y in range(num_parks):\n",
    "            agents = self.grid.get_cell_list_contents([(PARK,y)])\n",
    "            self.updateSpread(agents)\n",
    "        # Grocery\n",
    "        for y in range(num_grocery_stores):\n",
    "            agents = self.grid.get_cell_list_contents([(GROCERY_STORE,y)])\n",
    "            self.updateSpread(agents)\n",
    "        # Home\n",
    "        for y in range(num_agents // agent_per_home):\n",
    "            agents = self.grid.get_cell_list_contents([(HOME,y)])\n",
    "            self.updateSpread(agents, True)\n",
    "    def updateSpread(self, agents, close_contact = False):\n",
    "        if any(a.health in (INFECTED_A, INFECTED_S, CRITICAL) for a in agents):\n",
    "            [a.infect(close_contact) for a in agents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "60c38d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_simulation(iteration, evaluate):\n",
    "    model = SimulationModel(num_agents, iteration, evaluate)\n",
    "    for i in range(num_steps):\n",
    "        model.step()\n",
    "    modelDF = model.datacollector.get_model_vars_dataframe()\n",
    "    return model.deceasedCount#, modelDF.infected, modelDF.deceased, modelDF.home, modelDF.home_quarantine, modelDF.compliance, modelDF.violation, modelDF.vaccinated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "30f9cedb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|█▏                                                                               | 1/70 [01:04<1:14:09, 64.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|██▎                                                                              | 2/70 [01:59<1:06:28, 58.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|███▍                                                                             | 3/70 [02:55<1:04:19, 57.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|████▋                                                                            | 4/70 [03:52<1:03:13, 57.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|█████▊                                                                           | 5/70 [04:55<1:04:24, 59.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  9%|██████▉                                                                          | 6/70 [05:49<1:01:33, 57.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|████████                                                                         | 7/70 [06:51<1:01:44, 58.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 11%|█████████▎                                                                       | 8/70 [07:51<1:01:23, 59.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 13%|██████████▍                                                                      | 9/70 [08:58<1:02:37, 61.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 14%|███████████▍                                                                    | 10/70 [10:01<1:02:04, 62.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|████████████▌                                                                   | 11/70 [11:02<1:00:39, 61.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|█████████████▋                                                                  | 12/70 [12:12<1:02:19, 64.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 19%|██████████████▊                                                                 | 13/70 [13:23<1:02:56, 66.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|████████████████                                                                | 14/70 [14:33<1:03:02, 67.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 21%|█████████████████▏                                                              | 15/70 [15:35<1:00:23, 65.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 23%|██████████████████▋                                                               | 16/70 [16:39<58:45, 65.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|███████████████████▉                                                              | 17/70 [17:48<58:34, 66.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 26%|█████████████████████                                                             | 18/70 [18:57<58:06, 67.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 27%|██████████████████████▎                                                           | 19/70 [20:15<59:44, 70.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 29%|██████████████████████▊                                                         | 20/70 [21:38<1:01:56, 74.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|████████████████████████                                                        | 21/70 [22:56<1:01:37, 75.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 31%|█████████████████████████▊                                                        | 22/70 [24:08<59:34, 74.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|██████████████████████████▎                                                     | 23/70 [25:36<1:01:21, 78.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 34%|███████████████████████████▍                                                    | 24/70 [27:03<1:02:10, 81.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 36%|████████████████████████████▌                                                   | 25/70 [28:24<1:00:36, 80.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 37%|█████████████████████████████▋                                                  | 26/70 [30:00<1:02:44, 85.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 39%|███████████████████████████████▋                                                  | 27/70 [31:19<59:52, 83.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████████████████████████████████                                                | 28/70 [32:50<1:00:06, 85.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 41%|█████████████████████████████████▏                                              | 29/70 [34:27<1:00:51, 89.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 43%|███████████████████████████████████▏                                              | 30/70 [35:54<59:03, 88.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 44%|████████████████████████████████████▎                                             | 31/70 [37:27<58:19, 89.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 46%|█████████████████████████████████████▍                                            | 32/70 [39:01<57:36, 90.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 47%|█████████████████████████████████████▋                                          | 33/70 [40:56<1:00:38, 98.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 49%|██████████████████████████████████████▎                                        | 34/70 [42:42<1:00:19, 100.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|███████████████████████████████████████▌                                       | 35/70 [44:43<1:02:11, 106.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 51%|████████████████████████████████████████▋                                      | 36/70 [46:44<1:02:53, 110.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 53%|█████████████████████████████████████████▊                                     | 37/70 [49:11<1:07:03, 121.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 54%|██████████████████████████████████████████▉                                    | 38/70 [51:20<1:06:09, 124.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 56%|████████████████████████████████████████████                                   | 39/70 [53:48<1:07:44, 131.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 57%|█████████████████████████████████████████████▏                                 | 40/70 [56:08<1:06:55, 133.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 59%|██████████████████████████████████████████████▎                                | 41/70 [58:48<1:08:31, 141.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████████████████████████████████████████████▏                              | 42/70 [1:01:19<1:07:24, 144.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 61%|███████████████████████████████████████████████▎                             | 43/70 [1:03:59<1:07:08, 149.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 63%|████████████████████████████████████████████████▍                            | 44/70 [1:06:37<1:05:49, 151.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 64%|█████████████████████████████████████████████████▌                           | 45/70 [1:09:26<1:05:19, 156.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 66%|██████████████████████████████████████████████████▌                          | 46/70 [1:12:15<1:04:13, 160.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|███████████████████████████████████████████████████▋                         | 47/70 [1:15:09<1:03:05, 164.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 69%|████████████████████████████████████████████████████▊                        | 48/70 [1:18:02<1:01:15, 167.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|███████████████████████████████████████████████████████▎                       | 49/70 [1:21:02<59:52, 171.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 71%|████████████████████████████████████████████████████████▍                      | 50/70 [1:24:07<58:23, 175.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 73%|█████████████████████████████████████████████████████████▌                     | 51/70 [1:25:46<48:14, 152.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 74%|██████████████████████████████████████████████████████████▋                    | 52/70 [1:27:25<40:53, 136.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 76%|███████████████████████████████████████████████████████████▊                   | 53/70 [1:29:06<35:37, 125.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 77%|████████████████████████████████████████████████████████████▉                  | 54/70 [1:30:47<31:34, 118.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 79%|██████████████████████████████████████████████████████████████                 | 55/70 [1:32:29<28:18, 113.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|███████████████████████████████████████████████████████████████▏               | 56/70 [1:34:10<25:34, 109.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 81%|████████████████████████████████████████████████████████████████▎              | 57/70 [1:35:48<23:01, 106.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 83%|█████████████████████████████████████████████████████████████████▍             | 58/70 [1:37:27<20:50, 104.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 84%|██████████████████████████████████████████████████████████████████▌            | 59/70 [1:39:08<18:55, 103.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 86%|███████████████████████████████████████████████████████████████████▋           | 60/70 [1:40:50<17:06, 102.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 87%|████████████████████████████████████████████████████████████████████▊          | 61/70 [1:42:26<15:06, 100.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 89%|█████████████████████████████████████████████████████████████████████▉         | 62/70 [1:44:07<13:27, 100.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|███████████████████████████████████████████████████████████████████████        | 63/70 [1:45:46<11:42, 100.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 91%|█████████████████████████████████████████████████████████████████████████▏      | 64/70 [1:47:22<09:53, 98.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 93%|██████████████████████████████████████████████████████████████████████████▎     | 65/70 [1:49:03<08:17, 99.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 94%|███████████████████████████████████████████████████████████████████████████▍    | 66/70 [1:50:41<06:36, 99.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 96%|████████████████████████████████████████████████████████████████████████████▌   | 67/70 [1:52:22<04:58, 99.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 97%|█████████████████████████████████████████████████████████████████████████████▋  | 68/70 [1:53:58<03:17, 98.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 99%|██████████████████████████████████████████████████████████████████████████████▊ | 69/70 [1:55:38<01:39, 99.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 70/70 [1:57:19<00:00, 100.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "infected, deceased, quarantine, compliance, violation, ratio, vaccinated = None, None, None, None, None, None, None\n",
    "for i in tqdm(range(1, num_train_iterations + num_eval_iterations + 1)):\n",
    "#     deceasedCount, infected, deceased, home, home_quarantine, compliance, violation, vaccinated = run_simulation(i, True if i > num_train_iterations else False)\n",
    "    deceasedCount = run_simulation(i, True if i > num_train_iterations else False)\n",
    "    print('deceasedCount', deceasedCount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f11e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_infected = pd.Series(infected).to_frame()\n",
    "df_deceased = pd.Series(deceased).to_frame()\n",
    "df_home = pd.Series(home).to_frame()\n",
    "df_home_quarantine = pd.Series(home_quarantine).to_frame()\n",
    "df_compliance = pd.Series(compliance).to_frame()\n",
    "df_violation = pd.Series(violation).to_frame()\n",
    "# df_ratio = pd.Series(ratio).to_frame()\n",
    "df_vaccinated = pd.Series(vaccinated).to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c3d756",
   "metadata": {},
   "outputs": [],
   "source": [
    "rolling_frame = 1\n",
    "df_infected_rolling = df_infected.rolling(window = rolling_frame).mean()\n",
    "df_deceased_rolling = df_deceased.rolling(window = rolling_frame).mean()\n",
    "df_home_rolling = df_home.rolling(window = rolling_frame).mean()\n",
    "df_home_quarantine_rolling = df_home_quarantine.rolling(window = rolling_frame).mean()\n",
    "df_compliance_rolling = df_compliance.rolling(window = rolling_frame).mean()\n",
    "df_violation_rolling = df_violation.rolling(window = rolling_frame).mean()\n",
    "# df_ratio_rolling = df_ratio.rolling(window = rolling_frame).mean()\n",
    "df_vaccinated_rolling = df_vaccinated.rolling(window = rolling_frame).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "306a4ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "ins = df_infected.plot.line()\n",
    "ins.figure.savefig(\"{}{}\".format(figure_path, 'infected.pdf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40b251b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ins = df_deceased_rolling.plot.line()\n",
    "ins.figure.savefig(\"{}{}\".format(figure_path, 'deceased.pdf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5abf8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ins = df_compliance_rolling.plot.line()\n",
    "ins.figure.savefig(\"{}{}\".format(figure_path, 'compliance.pdf'))\n",
    "ins = df_violation_rolling.plot.line()\n",
    "ins.figure.savefig(\"{}{}\".format(figure_path, 'violation.pdf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc1a6c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ins = df_home_rolling.plot.line()\n",
    "ins.figure.savefig(\"{}{}\".format(figure_path, 'home.pdf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614e0fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ins = df_home_quarantine_rolling.plot.line()\n",
    "ins.figure.savefig(\"{}{}\".format(figure_path, 'quarantine.pdf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc89cde6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ins = df_vaccinated_rolling.plot.line()\n",
    "ins.figure.savefig(\"{}{}\".format(figure_path, 'vaccinated.pdf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d211ff80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3be1c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu",
   "language": "python",
   "name": "noe"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
