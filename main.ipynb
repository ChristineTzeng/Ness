{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a43748c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prescriptive norm: forced-quarantine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "906bf94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mesa import Agent, Model\n",
    "from mesa.time import RandomActivation, BaseScheduler\n",
    "from mesa.space import MultiGrid\n",
    "from mesa.datacollection import DataCollector\n",
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "import csv\n",
    "from statistics import mean\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from collections import deque\n",
    "import time\n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16c51d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Simulation Parameters ###\n",
    "\n",
    "file_name = 'primitive_prob'\n",
    "\n",
    "# general\n",
    "num_train_iterations = 50\n",
    "num_eval_iterations = 20\n",
    "num_steps = 2000\n",
    "num_agents = 100\n",
    "agent_per_home = 1\n",
    "\n",
    "startingState = 0.3\n",
    "vaccine_multiplier = 0.5\n",
    "home_recovery_multiplier = 2\n",
    "\n",
    "num_grocery_stores = 1\n",
    "num_parks = 1\n",
    "\n",
    "FQ_frames = 5\n",
    "\n",
    "# locations\n",
    "HOME = 0\n",
    "PARK = 1\n",
    "GROCERY_STORE = 2\n",
    "HOSPITAL = 3\n",
    "\n",
    "# emotion\n",
    "POSITIVE = 1\n",
    "NEUTRAL = 0\n",
    "NEGATIVE = -1\n",
    "\n",
    "vaccine_last = num_steps#10\n",
    "\n",
    "location_space = [HOME, PARK, GROCERY_STORE, HOSPITAL]\n",
    "\n",
    "NOT_INFECTED = 0\n",
    "INFECTED_A = 1\n",
    "INFECTED_S = 2\n",
    "CRITICAL = 3\n",
    "DECEASED = 4\n",
    "\n",
    "health_space = [NOT_INFECTED, INFECTED_A, INFECTED_S, CRITICAL, DECEASED]\n",
    "\n",
    "evolve_prob = [0.8, 0.36, 0.01, 0.2, 0]\n",
    "recover_prob = [0, 0.2, 0.1, 0.05, 0]\n",
    "\n",
    "#oberve prob\n",
    "N_prob = [0.8,0,0.9,1]\n",
    "A_prob = [0.5,0,1,1]\n",
    "S_prob = [0.3,0,0.9,1]\n",
    "C_prob = [0.1,0,0.4,1]\n",
    "\n",
    "# trial distribution\n",
    "# N_prob = [0.6,0.8,0.9,1]\n",
    "# A_prob = [0.4,0.6,1,1]\n",
    "# S_prob = [0.2,0.4,0.9,1]\n",
    "# C_prob = [0.1,0.2,0.4,1]\n",
    "\n",
    "#signal distribution\n",
    "hard_sanctioning_prob = 0.0 #0.38 0.2\n",
    "message_sanctioning_prob = 0.0 #0 0.38\n",
    "emotion_sanctioning_prob = 0.0 # 0 0.38\n",
    "sanction_prob_w_health = [0,0,0.5,0.8]\n",
    "\n",
    "# message_prob: prob for sanction 20% message(belief reward) 38% \n",
    "# emote_prob: prob for sanction 20% emotion 38%\n",
    "# hint_prob: prob for sanction 20% emotion 38%\n",
    "# hint_balance: prob for sanction 20% emotion 38%\n",
    "\n",
    "# sanction_weighted: prob for sanction 28%\n",
    "# message_weighted: prob for sanction 20% message 16% \n",
    "# feeling_weighted: prob for sanction 20% emotion 16%\n",
    "# hint_weighted: prob for sanction 20% emotion 10%   -> 10 * 0.5 + 10 * 0.3\n",
    " \n",
    "# desire/intention\n",
    "stay_home = 0\n",
    "go_outdoors = 1\n",
    "go_shopping = 2\n",
    "\n",
    "intention_space = [stay_home, go_outdoors, go_shopping]\n",
    "\n",
    "# actions\n",
    "MOVE_HOME = 0\n",
    "MOVE_PARK = 1\n",
    "MOVE_STORE = 2\n",
    "MOVE_HOSPITAL = 3\n",
    "\n",
    "action_space = [MOVE_HOME, MOVE_PARK, MOVE_STORE, MOVE_HOSPITAL]\n",
    "sanction_space = ['location', 'health']\n",
    "\n",
    "env_path = ''\n",
    "figure_path = env_path + 'figures/' + file_name + '/'\n",
    "logs_path = env_path + 'logs/' + file_name + '/'\n",
    "\n",
    "lr = 0.001#0.00025\n",
    "gamma = 0.9\n",
    "epsilon_greedy = 0.9\n",
    "epsilon_min = 0.1\n",
    "\n",
    "agent_type_primitive = 1\n",
    "agent_type_sanctioning = 2\n",
    "agent_type_message = 3\n",
    "agent_type_emote = 4\n",
    "agent_type_hint = 5\n",
    "\n",
    "# define agent society in simulation\n",
    "agent_type = agent_type_primitive\n",
    "\n",
    "SELF = 0\n",
    "OTHERS = 1\n",
    "\n",
    "sanction_payoff = 1.0\n",
    "emotion_payoff = 0.5\n",
    "\n",
    "# tuples of norms\n",
    "norm = {\n",
    "            \"type\": \"prohibition\",\n",
    "            \"subject\": SELF,\n",
    "            \"object\": OTHERS,\n",
    "            \"antecedent\": {\n",
    "                \"location\": [PARK, GROCERY_STORE, HOSPITAL],\n",
    "                \"attribute\": \"perceived_health\",\n",
    "                \"value\": [INFECTED_S, CRITICAL]\n",
    "            }, \n",
    "            \"consequent\": {\n",
    "                \"emotion\": -0.3, \n",
    "                \"message\": -0.5,\n",
    "                \"hard_sanction\": -1\n",
    "            }\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73984878",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The basic Q learning model\n",
    "class RL(object):\n",
    "    def __init__(self, actions):\n",
    "        self.actions = actions\n",
    "        self.lr = lr\n",
    "        self.gamma = gamma\n",
    "        self.epsilon_greedy = epsilon_greedy\n",
    "        \n",
    "        self.q_table = pd.DataFrame(columns = self.actions, dtype = np.float64)\n",
    "    \n",
    "    def instantialize(self):\n",
    "        return\n",
    "    \n",
    "    def check_state_exist(self, state):\n",
    "        if state not in self.q_table.index:\n",
    "            self.q_table.loc[state] = pd.Series(\n",
    "                [0] * len(self.actions),\n",
    "                index = self.q_table.columns\n",
    "                )\n",
    "\n",
    "    def action_select(self, state, n_iteration, evaluate):\n",
    "        self.check_state_exist(state)\n",
    "        if evaluate or (np.random.uniform() > 0.9 * (num_train_iterations - n_iteration) / num_train_iterations):\n",
    "            actions= self.q_table.loc[state, :]\n",
    "            action = np.random.choice(actions[actions == np.max(actions)].index)\n",
    "        else:\n",
    "            action = np.random.choice(action_space)\n",
    "        return action\n",
    "    \n",
    "    def getQ(self, state, action):\n",
    "        return self.q_table((state, action), 0.0)\n",
    "\n",
    "class QLearningTable(RL):\n",
    "    def __init__(self, actions):\n",
    "        super(QLearningTable, self).__init__(actions)\n",
    "    \n",
    "    def learn(self, s, a, r, s_):\n",
    "        self.check_state_exist(s_)\n",
    "        q_predict = self.q_table.loc[s, a]\n",
    "        q_target = r + self.gamma * self.q_table.loc[s_, :].max()\n",
    "        # check NaN\n",
    "        q_target = 0 if np.isnan(q_target) else q_target\n",
    "        self.q_table.loc[s, a] += self.lr * (q_target - q_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "185be85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "RL_brain = QLearningTable(actions = list(range(len(action_space))))\n",
    "Sanction_brain = QLearningTable(actions = list(range(len(sanction_space))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a64e9c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HumanAgent(Agent):\n",
    "    \"\"\"The actor in the simulation.\"\"\"\n",
    "    def __init__(self, unique_id, model, evaluate):\n",
    "        super().__init__(unique_id, model)\n",
    "        \n",
    "        self.homeId = unique_id // agent_per_home\n",
    "        self.health = NOT_INFECTED\n",
    "        self.perceived_health = NOT_INFECTED\n",
    "        \n",
    "        self.x = HOME\n",
    "        self.y = unique_id // agent_per_home\n",
    "        \n",
    "        self.infected_times = 0\n",
    "        \n",
    "        self.external_reward = 0\n",
    "        \n",
    "        self.FQ_frames = 0\n",
    "        \n",
    "        self.last_action = None\n",
    "        \n",
    "        self.vaccinated = False\n",
    "        self.vaccine_last = 0\n",
    "        self.intention = 0\n",
    "        self.self_directed_emotion = 0\n",
    "        self.other_directed_emotion = 0\n",
    "        \n",
    "        self.evaluate = evaluate\n",
    "        self.reward = 0\n",
    "        \n",
    "        self.reset_death = False\n",
    "    \n",
    "    def initialize(self):\n",
    "        self.state = self.get_state(0)\n",
    "    \n",
    "    def step(self):\n",
    "        \n",
    "        if self.health != DECEASED:\n",
    "            self.act()\n",
    "        self.updateHealth()\n",
    "    \n",
    "    # observation\n",
    "    def get_state(self, env_emotion = None):\n",
    "        loc_x, loc_y = self.pos\n",
    "        return [loc_x, loc_y, self.health, self.intention, self.FQ_frames, self.vaccinated, self.vaccine_last]\n",
    "    \n",
    "    # symptom progress\n",
    "    def updateHealth(self):\n",
    "        if self.health == DECEASED:\n",
    "           return\n",
    "\n",
    "        x,y = self.pos\n",
    "        \n",
    "        if self.health in (INFECTED_A, INFECTED_S, CRITICAL):\n",
    "            p = self.random.uniform(0, 1)\n",
    "            ev_prob = evolve_prob[self.health] * (vaccine_multiplier if self.vaccinated else 1)\n",
    "            rec_prob = recover_prob[self.health] * (home_recovery_multiplier if x == HOME else 1)\n",
    "            if p < ev_prob:\n",
    "                self.health += 1\n",
    "            elif p < ev_prob + rec_prob:\n",
    "                self.health = NOT_INFECTED\n",
    "            \n",
    "            if self.health == NOT_INFECTED:\n",
    "                if p < N_prob[NOT_INFECTED]:\n",
    "                    self.perceived_health = NOT_INFECTED\n",
    "                elif p < N_prob[INFECTED_A]:\n",
    "                    self.perceived_health = INFECTED_A\n",
    "                elif p < N_prob[INFECTED_S]:\n",
    "                    self.perceived_health = INFECTED_S\n",
    "                elif p < N_prob[CRITICAL]:\n",
    "                    self.perceived_health = CRITICAL\n",
    "            elif self.health == INFECTED_A:\n",
    "                if p < A_prob[NOT_INFECTED]:\n",
    "                    self.perceived_health = NOT_INFECTED\n",
    "                elif p < A_prob[INFECTED_A]:\n",
    "                    self.perceived_health = INFECTED_A\n",
    "                elif p < A_prob[INFECTED_S]:\n",
    "                    self.perceived_health = INFECTED_S\n",
    "                elif p < A_prob[CRITICAL]:\n",
    "                    self.perceived_health = CRITICAL        \n",
    "            elif self.health == INFECTED_S:\n",
    "                if p < S_prob[NOT_INFECTED]:\n",
    "                    self.perceived_health = NOT_INFECTED\n",
    "                elif p < S_prob[INFECTED_A]:\n",
    "                    self.perceived_health = INFECTED_A\n",
    "                elif p < S_prob[INFECTED_S]:\n",
    "                    self.perceived_health = INFECTED_S\n",
    "                elif p < S_prob[CRITICAL]:\n",
    "                    self.perceived_health = CRITICAL\n",
    "            elif self.health == CRITICAL:\n",
    "                if p < C_prob[NOT_INFECTED]:\n",
    "                    self.perceived_health = NOT_INFECTED\n",
    "                elif p < C_prob[INFECTED_A]:\n",
    "                    self.perceived_health = INFECTED_A\n",
    "                elif p < C_prob[INFECTED_S]:\n",
    "                    self.perceived_health = INFECTED_S\n",
    "                elif p < C_prob[CRITICAL]:\n",
    "                    self.perceived_health = CRITICAL\n",
    "            elif self.health == DECEASED:\n",
    "                self.model.deceasedCount += 1\n",
    "                self.perceived_health = DECEASED\n",
    "                self.reset_death = True\n",
    "                return\n",
    "            \n",
    "            \n",
    "                    \n",
    "        if self.FQ_frames > 0:\n",
    "            self.FQ_frames -= 1\n",
    "        return\n",
    "    \n",
    "    def perceive(self):\n",
    "        x, y = self.pos\n",
    "        return self.model.perceive(x, y, self.unique_id)\n",
    "    \n",
    "    # infect with a probability when interact\n",
    "    def infect(self, close_contact):\n",
    "        p = self.random.uniform(0, 1)\n",
    "        if self.health == NOT_INFECTED:\n",
    "            if close_contact:\n",
    "                self.health += 1\n",
    "                self.infected_times += 1\n",
    "            else:\n",
    "                # disease proceed with different rate\n",
    "                if p < (evolve_prob[NOT_INFECTED] * vaccine_multiplier) and self.vaccinated:\n",
    "                    self.health += 1\n",
    "                    self.infected_times += 1\n",
    "                elif p < evolve_prob[NOT_INFECTED] and not self.vaccinated:\n",
    "                    self.health += 1\n",
    "                    self.infected_times += 1\n",
    "    \n",
    "    def act(self):\n",
    "        x, y = self.pos\n",
    "        \n",
    "        # action selection\n",
    "        self.intention = np.random.choice(intention_space)\n",
    "        \n",
    "        if self.FQ_frames > 0:\n",
    "            self.last_action = MOVE_HOME\n",
    "            if x != HOME:\n",
    "                self.model.grid.move_agent(self, (HOME, self.unique_id // agent_per_home))\n",
    "                self.x = HOME\n",
    "                self.y = self.unique_id // agent_per_home\n",
    "        else:\n",
    "            action = RL_brain.action_select(str(self.state), self.model.iteration, self.evaluate)\n",
    "            # run action\n",
    "            if action == MOVE_HOME:\n",
    "                self.model.grid.move_agent(self, (HOME, self.unique_id // agent_per_home))\n",
    "                self.x = HOME\n",
    "                self.y = self.unique_id // agent_per_home\n",
    "            elif action == MOVE_STORE:\n",
    "                rd = self.random.randint(0, num_grocery_stores - 1)\n",
    "                self.model.grid.move_agent(self, (GROCERY_STORE, rd))\n",
    "                self.x = GROCERY_STORE\n",
    "                self.y = rd\n",
    "            elif action == MOVE_PARK:\n",
    "                rd = self.random.randint(0, num_parks - 1)\n",
    "                self.model.grid.move_agent(self, (PARK, self.random.randint(0, num_parks - 1)))\n",
    "                self.x = PARK\n",
    "                self.y = rd\n",
    "            elif action == MOVE_HOSPITAL:\n",
    "                self.model.grid.move_agent(self, (HOSPITAL, 0))\n",
    "                self.x = HOSPITAL\n",
    "                self.y = 0\n",
    "                self.vaccinated = True\n",
    "                self.vaccine_last = vaccine_last\n",
    " \n",
    "            self.last_action = action\n",
    "\n",
    "        if agent_type in (agent_type_emote, agent_type_hint):\n",
    "            self.elicit_emotion(self.intention)\n",
    "    \n",
    "    # elicit self-directed emotion\n",
    "    def elicit_emotion(self, intention):\n",
    "        x, y = self.pos\n",
    "        \n",
    "        # trigger unpleasant while being forced to stay at home\n",
    "        if x == HOME and self.FQ_frames > 0:\n",
    "            self.self_directed_emotion = -emotion_payoff\n",
    "        # trigger guilty based on norms\n",
    "        else:\n",
    "            emotion = (1 if x == intention else -1)\n",
    "            if x != HOME and self.health > 0:\n",
    "                emotion += -emotion_payoff\n",
    "            elif x == HOME and self.health > 0:\n",
    "                emotion += emotion_payoff\n",
    "    \n",
    "            if emotion > emotion_payoff: emotion = emotion_payoff\n",
    "            if emotion < -emotion_payoff: emotion = -emotion_payoff\n",
    "            self.self_directed_emotion = emotion\n",
    "        \n",
    "\n",
    "    def learn(self, force = False):\n",
    "        x, y = self.pos\n",
    "        pre_state = self.state\n",
    "        \n",
    "        self.reward = 0\n",
    "        env_emotion = 0\n",
    "        \n",
    "        if agent_type in (agent_type_emote, agent_type_hint):\n",
    "            self.state = self.get_state(0)\n",
    "        else:\n",
    "            self.state = self.get_state(0)\n",
    "        \n",
    "        if self.health == DECEASED and not self.reset_death:\n",
    "            if self.x != HOME or self.x != -1:\n",
    "                self.model.grid.move_agent(self, (HOME, self.unique_id // agent_per_home))\n",
    "                self.x = HOME\n",
    "                self.y = self.unique_id // agent_per_home\n",
    "            self.reward, self.FQ_frames = 0, 0\n",
    "            self.self_directed_emotion, self.other_directed_emotion = 0, 0\n",
    "            self.intention, self.last_action, self.x, self.y = -1, -1, -1, -1\n",
    "            return\n",
    "        \n",
    "        reward = -2 if self.health == DECEASED else 0\n",
    "        \n",
    "        if self.FQ_frames > 0:\n",
    "            reward -= 1\n",
    "        \n",
    "        reward += 1 if self.intention == x else -1\n",
    "        \n",
    "        if agent_type in (agent_type_emote, agent_type_hint):\n",
    "            reward += (self.self_directed_emotion + self.other_directed_emotion)\n",
    "        \n",
    "        reward += self.external_reward\n",
    "        \n",
    "        self.reward = reward\n",
    "        \n",
    "        self.reset_death = False\n",
    "        self.external_reward = 0\n",
    "        \n",
    "        if self.evaluate:\n",
    "            return\n",
    "        \n",
    "        RL_brain.learn(str(pre_state), self.last_action, reward, str(self.state))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8fe18820",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimulationModel(Model):\n",
    "    \"\"\"The model runs the simulation.\"\"\"\n",
    "    def __init__(self, N, iteration, evaluate):\n",
    "        self.num_agents = N\n",
    "        self.random.seed(1)\n",
    "        self.evaluate = evaluate\n",
    "        \n",
    "        self.grid = MultiGrid(5, num_agents // agent_per_home, False)\n",
    "        self.schedule = RandomActivation(self)\n",
    "        self.iteration = iteration\n",
    "        \n",
    "        self.deceasedCount = 0\n",
    "        \n",
    "        self.datacollector = DataCollector(\n",
    "            model_reporters={\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        self.reset()\n",
    "    \n",
    "    def reset(self):\n",
    "        if self.schedule.get_agent_count() > 0:\n",
    "            for agent in self.schedule.agents:\n",
    "                self.schedule.remove(agent)\n",
    "        # load agents\n",
    "        for i in range(self.num_agents):\n",
    "            a = HumanAgent(i, self, self.evaluate)\n",
    "            self.schedule.add(a)\n",
    "            self.grid.place_agent(a, (HOME, 0))\n",
    "        \n",
    "        for a in self.random.sample(self.schedule.agents, int(startingState * self.num_agents)):\n",
    "            a.health = INFECTED_A\n",
    "            a.infected_times += 1\n",
    "        \n",
    "        for agent in self.schedule.agents:\n",
    "            agent.initialize()\n",
    "        \n",
    "        self.deceased_count = 0\n",
    "        self.violation_count = 0\n",
    "        self.compliance_count = 0\n",
    "        self.cumulative_deceased = 0\n",
    "        self.cumulative_violation = 0\n",
    "        self.cumulative_compliance = 0\n",
    "    \n",
    "    def run_norms(self):\n",
    "        emotion_saction_set, message_sanction_set, hard_saction_set = set(), set(), set()\n",
    "        # Home\n",
    "        for y in range(num_agents // agent_per_home):\n",
    "            agents = self.grid.get_cell_list_contents([(HOME,y)])\n",
    "            comply_agents = [agent for agent in agents if agent.health != DECEASED and agent.perceived_health != NOT_INFECTED and agent.FQ_frames == 0 ]\n",
    "            for agent in comply_agents:\n",
    "                agent.external_reward -= norm.get(\"consequent\").get(\"hard_sanction\")\n",
    "                if agent_type in (agent_type_hint, agent_type_emote):\n",
    "                    agent.other_directed_emotion = emotion_payoff\n",
    "        # Park\n",
    "        if PARK in norm.get(\"antecedent\").get(\"location\"):\n",
    "            for y in range(num_parks):\n",
    "                agents = self.grid.get_cell_list_contents([(PARK,y)])\n",
    "                agents = [agent for agent in agents if agent.health != DECEASED ]\n",
    "                violate_agents = [agent for agent in agents if getattr(agent, norm.get(\"antecedent\").get(\"attribute\")) in norm.get(\"antecedent\").get(\"value\") ]\n",
    "                \n",
    "                if len(agents) - len(violate_agents) > 0:\n",
    "                    for agent in violate_agents:\n",
    "                        sanctioners = [sanctioner for sanctioner in agents if sanctioner.health == NOT_INFECTED and sanctioner.unique_id != agent.unique_id]    \n",
    "\n",
    "                        hard_sanction, sanction = False, False\n",
    "                        p = self.random.uniform(0, 1)\n",
    "                        if p < sanction_prob_w_health[agent.perceived_health]:\n",
    "                            p = self.random.uniform(0, 1)\n",
    "                            if p < hard_sanctioning_prob:\n",
    "                                agent.FQ_frames = FQ_frames\n",
    "                                hard_sanction = True\n",
    "                            \n",
    "                            elif agent_type == agent_type_message:\n",
    "                                if p < message_sanctioning_prob:\n",
    "                                    sanction = True\n",
    "                                    agent.external_reward += norm.get(\"consequent\").get(\"message\")\n",
    "                            elif agent_type in (agent_type_hint, agent_type_emote):\n",
    "                                if p < emotion_sanctioning_prob:\n",
    "                                    sanction = True\n",
    "                                    if agent_type == agent_type_hint:\n",
    "                                        agent.external_reward += norm.get(\"consequent\").get(\"emotion\")\n",
    "                                    agent.other_directed_emotion = -emotion_payoff\n",
    "\n",
    "                        if agent_type in (agent_type_hint, agent_type_emote) and sanction:\n",
    "                            for sanctioner in sanctioners:\n",
    "                                if sanctioner.unique_id not in emotion_saction_set:\n",
    "                                    emotion_saction_set.add(sanctioner.unique_id)\n",
    "                                    sanctioner.other_directed_emotion = 0\n",
    "\n",
    "        # Grocery\n",
    "        if GROCERY_STORE in norm.get(\"antecedent\").get(\"location\"):\n",
    "            for y in range(num_grocery_stores):\n",
    "                agents = self.grid.get_cell_list_contents([(GROCERY_STORE,y)])\n",
    "                agents = [agent for agent in agents if agent.health != DECEASED ]\n",
    "                violate_agents = [agent for agent in agents if getattr(agent, norm.get(\"antecedent\").get(\"attribute\")) in norm.get(\"antecedent\").get(\"value\") ]\n",
    "                \n",
    "                if len(agents) - len(violate_agents) > 0:\n",
    "                    for agent in violate_agents:\n",
    "                        sanctioners = [sanctioner for sanctioner in agents if sanctioner.health == NOT_INFECTED and sanctioner.unique_id != agent.unique_id]    \n",
    "                        \n",
    "                        hard_sanction, sanction = False, False\n",
    "                        p = self.random.uniform(0, 1)\n",
    "                        if p < sanction_prob_w_health[agent.perceived_health]:\n",
    "                            p = self.random.uniform(0, 1)\n",
    "                            if p < hard_sanctioning_prob:\n",
    "                                agent.FQ_frames = FQ_frames\n",
    "                                hard_sanction = True\n",
    "                            \n",
    "                            elif agent_type == agent_type_message:\n",
    "                                if p < message_sanctioning_prob:\n",
    "                                    sanction = True\n",
    "                                    agent.external_reward += norm.get(\"consequent\").get(\"message\")\n",
    "                            elif agent_type in (agent_type_hint, agent_type_emote):\n",
    "                                if p < emotion_sanctioning_prob:\n",
    "                                    sanction = True\n",
    "                                    if agent_type == agent_type_hint:\n",
    "                                        agent.external_reward += norm.get(\"consequent\").get(\"emotion\")\n",
    "                                    agent.other_directed_emotion = -emotion_payoff\n",
    "\n",
    "                        if agent_type in (agent_type_hint, agent_type_emote) and sanction:\n",
    "                            for sanctioner in sanctioners:\n",
    "                                if sanctioner.unique_id not in emotion_saction_set:\n",
    "                                    emotion_saction_set.add(sanctioner.unique_id)\n",
    "                                    sanctioner.other_directed_emotion = 0\n",
    "\n",
    "            \n",
    "        if HOSPITAL in norm.get(\"antecedent\").get(\"location\"):\n",
    "            agents = self.grid.get_cell_list_contents([(HOSPITAL,0)])\n",
    "            agents = [agent for agent in agents if agent.health != DECEASED ]\n",
    "            violate_agents = [agent for agent in agents if getattr(agent, norm.get(\"antecedent\").get(\"attribute\")) in norm.get(\"antecedent\").get(\"value\") ]\n",
    "            \n",
    "            if len(agents) - len(violate_agents) > 0:\n",
    "                for agent in violate_agents:\n",
    "                    sanctioners = [sanctioner for sanctioner in agents if sanctioner.health == NOT_INFECTED and sanctioner.unique_id != agent.unique_id]\n",
    "                    \n",
    "                    hard_sanction, sanction = False, False\n",
    "                    p = self.random.uniform(0, 1)\n",
    "                    if p < sanction_prob_w_health[agent.perceived_health]:\n",
    "                        p = self.random.uniform(0, 1)\n",
    "                        if p < hard_sanctioning_prob:\n",
    "                            agent.FQ_frames = FQ_frames\n",
    "                            hard_sanction = True\n",
    "                            \n",
    "                        elif agent_type == agent_type_message:\n",
    "                            if p < message_sanctioning_prob:\n",
    "                                sanction = True\n",
    "                                agent.external_reward += norm.get(\"consequent\").get(\"message\")\n",
    "                        elif agent_type in (agent_type_hint, agent_type_emote):\n",
    "                            if p < emotion_sanctioning_prob:\n",
    "                                sanction = True\n",
    "                                if agent_type == agent_type_hint:\n",
    "                                    agent.external_reward += norm.get(\"consequent\").get(\"emotion\")\n",
    "                                agent.other_directed_emotion = -emotion_payoff\n",
    "                \n",
    "                    if agent_type in (agent_type_hint, agent_type_emote) and sanction:\n",
    "                        for sanctioner in sanctioners:\n",
    "                            if sanctioner.unique_id not in emotion_saction_set:\n",
    "                                emotion_saction_set.add(sanctioner.unique_id)\n",
    "                                sanctioner.other_directed_emotion = 0\n",
    "\n",
    "    def perceive(self, x, y, agent_id):\n",
    "        agents = self.grid.get_cell_list_contents([(x, y)])\n",
    "        emotions = [agent.other_directed_emotion for agent in agents if agent.unique_id != agent_id]\n",
    "        return sum(emotions)/len(emotions) if len(emotions) > 0 else 0\n",
    "    \n",
    "    def learn(self):\n",
    "        for i in range(self.num_agents):\n",
    "            agent = self.schedule._agents[i]\n",
    "            agent.learn()\n",
    "    \n",
    "    def compute_infected(self):\n",
    "        infectedAgents = [agent for agent in self.schedule.agents if agent.health in (INFECTED_A, INFECTED_S, CRITICAL) ]\n",
    "        return len(infectedAgents)\n",
    "    \n",
    "    def compute_deceased(self):\n",
    "        deceasedAgents = [agent for agent in self.schedule.agents if agent.health == DECEASED ]\n",
    "        return len(deceasedAgents)\n",
    "    \n",
    "    def compute_compliance(self):\n",
    "        agents = [agent for agent in self.schedule.agents if agent.last_action == MOVE_HOME and agent.health not in (NOT_INFECTED, DECEASED) ]\n",
    "        return len(agents)\n",
    "    \n",
    "    def compute_violation(self):\n",
    "        agents = [agent for agent in self.schedule.agents if agent.last_action != MOVE_HOME and agent.health not in (NOT_INFECTED, DECEASED) ]\n",
    "        return len(agents)\n",
    "    \n",
    "    def compute_compliance_rate(self):\n",
    "        comp = self.compute_compliance()\n",
    "        vio = self.compute_violation()\n",
    "        return comp / (comp + vio) if comp + vio > 0 else 0\n",
    "    \n",
    "    def compute_vaccinated(self):\n",
    "        agents = [agent for agent in self.schedule.agents if agent.vaccinated and agent.health != DECEASED ]\n",
    "        return len(agents)\n",
    "    \n",
    "    def compute_QC(self):\n",
    "        count = 0\n",
    "        for y in range(num_agents // agent_per_home):\n",
    "            agents = self.grid.get_cell_list_contents([(HOME,y)])\n",
    "            count += len(agents)\n",
    "        return count\n",
    "    \n",
    "    def compute_FQ(self):\n",
    "        count = 0\n",
    "        for y in range(num_agents // agent_per_home):\n",
    "            agents = self.grid.get_cell_list_contents([(HOME,y)])\n",
    "            agents = [agent for agent in agents if agent.FQ_frames > 1]\n",
    "            count += len(agents)\n",
    "        return count\n",
    "    \n",
    "    def step(self):\n",
    "        self.schedule.step()\n",
    "        if agent_type != agent_type_primitive:\n",
    "            self.run_norms()\n",
    "        self.identifyAgentsAndUpdateSpread()\n",
    "        self.learn()\n",
    "        self.write_csv()\n",
    "        self.datacollector.collect(self)\n",
    "        self.decay_emotion()\n",
    "    \n",
    "    def decay_emotion(self):\n",
    "        for i in range(self.num_agents):\n",
    "            agent = self.schedule._agents[i]\n",
    "            agent.other_directed_emotion = 0\n",
    "            agent.self_directed_emotion = 0\n",
    "\n",
    "    def write_csv(self):\n",
    "        if self.iteration <= num_train_iterations:\n",
    "            return\n",
    "        \n",
    "        with open(logs_path + file_name + '_agent.csv', 'a', newline = '') as agent_file:\n",
    "            writer = csv.writer(agent_file, delimiter = ',')\n",
    "            for i in range(self.num_agents):\n",
    "                agent = self.schedule._agents[i]\n",
    "                if agent_type in (agent_type_primitive, agent_type_sanctioning):\n",
    "                    writer.writerow([self.iteration, self.schedule.steps, agent.unique_id, agent.health, agent.infected_times, agent.reward, agent.FQ_frames, agent.vaccinated, agent.vaccine_last, agent.intention, agent.last_action, agent.x, agent.y, agent.self_directed_emotion, agent.other_directed_emotion])\n",
    "                elif agent_type == agent_type_message:\n",
    "                    writer.writerow([self.iteration, self.schedule.steps, agent.unique_id, agent.health, agent.infected_times, agent.reward, agent.FQ_frames, agent.vaccinated, agent.vaccine_last, agent.intention, agent.last_action, agent.x, agent.y, agent.self_directed_emotion, agent.other_directed_emotion])\n",
    "                elif agent_type == agent_type_emote:\n",
    "                    writer.writerow([self.iteration, self.schedule.steps, agent.unique_id, agent.health, agent.infected_times, agent.reward, agent.FQ_frames, agent.vaccinated, agent.vaccine_last, agent.intention, agent.last_action, agent.x, agent.y, agent.self_directed_emotion, agent.other_directed_emotion])\n",
    "                else:\n",
    "                    writer.writerow([self.iteration, self.schedule.steps, agent.unique_id, agent.health, agent.infected_times, agent.reward, agent.FQ_frames, agent.vaccinated, agent.vaccine_last, agent.intention, agent.last_action, agent.x, agent.y, agent.self_directed_emotion, agent.other_directed_emotion])\n",
    "        agent_file.close()\n",
    "    \n",
    "    def identifyAgentsAndUpdateSpread(self):\n",
    "        # Park\n",
    "        for y in range(num_parks):\n",
    "            agents = self.grid.get_cell_list_contents([(PARK,y)])\n",
    "            self.updateSpread(agents)\n",
    "        # Grocery\n",
    "        for y in range(num_grocery_stores):\n",
    "            agents = self.grid.get_cell_list_contents([(GROCERY_STORE,y)])\n",
    "            self.updateSpread(agents)\n",
    "        # Home\n",
    "        for y in range(num_agents // agent_per_home):\n",
    "            agents = self.grid.get_cell_list_contents([(HOME,y)])\n",
    "            self.updateSpread(agents, True)\n",
    "    def updateSpread(self, agents, close_contact = False):\n",
    "        if any(a.health in (INFECTED_A, INFECTED_S, CRITICAL) for a in agents):\n",
    "            [a.infect(close_contact) for a in agents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "60c38d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_simulation(iteration, evaluate):\n",
    "    model = SimulationModel(num_agents, iteration, evaluate)\n",
    "    for i in range(num_steps):\n",
    "        model.step()\n",
    "    modelDF = model.datacollector.get_model_vars_dataframe()\n",
    "    return model.deceasedCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "30f9cedb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|█▏                                                                                 | 1/70 [00:41<47:38, 41.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|██▎                                                                                | 2/70 [01:24<47:51, 42.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|███▌                                                                               | 3/70 [02:04<45:54, 41.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|████▋                                                                              | 4/70 [02:45<45:26, 41.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|█████▉                                                                             | 5/70 [03:32<47:01, 43.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  9%|███████                                                                            | 6/70 [04:18<47:08, 44.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|████████▎                                                                          | 7/70 [05:03<46:47, 44.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 11%|█████████▍                                                                         | 8/70 [05:52<47:23, 45.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 13%|██████████▋                                                                        | 9/70 [06:41<47:40, 46.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 14%|███████████▋                                                                      | 10/70 [07:24<45:36, 45.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|████████████▉                                                                     | 11/70 [08:20<47:57, 48.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|██████████████                                                                    | 12/70 [09:08<46:51, 48.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 19%|███████████████▏                                                                  | 13/70 [10:05<48:38, 51.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|████████████████▍                                                                 | 14/70 [11:00<48:53, 52.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 21%|█████████████████▌                                                                | 15/70 [11:52<47:52, 52.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 23%|██████████████████▋                                                               | 16/70 [12:52<49:09, 54.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|███████████████████▉                                                              | 17/70 [13:49<48:54, 55.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 26%|█████████████████████                                                             | 18/70 [14:48<48:58, 56.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 27%|██████████████████████▎                                                           | 19/70 [15:42<47:14, 55.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 29%|███████████████████████▍                                                          | 20/70 [16:41<47:09, 56.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|████████████████████████▌                                                         | 21/70 [17:48<48:50, 59.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 31%|█████████████████████████▊                                                        | 22/70 [18:49<48:09, 60.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|██████████████████████████▉                                                       | 23/70 [19:50<47:10, 60.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 34%|████████████████████████████                                                      | 24/70 [20:50<46:18, 60.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 36%|█████████████████████████████▎                                                    | 25/70 [21:52<45:32, 60.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 37%|██████████████████████████████▍                                                   | 26/70 [22:55<44:58, 61.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 39%|███████████████████████████████▋                                                  | 27/70 [24:06<46:01, 64.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████████████████████████████████▊                                                 | 28/70 [25:11<45:10, 64.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 41%|█████████████████████████████████▉                                                | 29/70 [26:12<43:21, 63.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 43%|███████████████████████████████████▏                                              | 30/70 [27:17<42:39, 63.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 44%|████████████████████████████████████▎                                             | 31/70 [28:30<43:20, 66.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 46%|█████████████████████████████████████▍                                            | 32/70 [29:43<43:24, 68.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 47%|██████████████████████████████████████▋                                           | 33/70 [30:52<42:23, 68.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 49%|███████████████████████████████████████▊                                          | 34/70 [32:03<41:33, 69.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████████████████████████████████████████                                         | 35/70 [33:20<41:50, 71.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 51%|██████████████████████████████████████████▏                                       | 36/70 [34:34<40:59, 72.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 53%|███████████████████████████████████████████▎                                      | 37/70 [35:49<40:19, 73.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 54%|████████████████████████████████████████████▌                                     | 38/70 [37:07<39:43, 74.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 56%|█████████████████████████████████████████████▋                                    | 39/70 [38:30<39:52, 77.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 57%|██████████████████████████████████████████████▊                                   | 40/70 [39:50<38:57, 77.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 59%|████████████████████████████████████████████████                                  | 41/70 [41:15<38:47, 80.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|█████████████████████████████████████████████████▏                                | 42/70 [42:31<36:49, 78.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 61%|██████████████████████████████████████████████████▎                               | 43/70 [43:49<35:23, 78.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 63%|███████████████████████████████████████████████████▌                              | 44/70 [45:08<34:03, 78.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 64%|████████████████████████████████████████████████████▋                             | 45/70 [46:26<32:43, 78.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 66%|█████████████████████████████████████████████████████▉                            | 46/70 [47:42<31:06, 77.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|███████████████████████████████████████████████████████                           | 47/70 [49:09<30:53, 80.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 69%|████████████████████████████████████████████████████████▏                         | 48/70 [50:26<29:09, 79.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|█████████████████████████████████████████████████████████▍                        | 49/70 [51:49<28:09, 80.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 71%|██████████████████████████████████████████████████████████▌                       | 50/70 [53:14<27:16, 81.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 73%|███████████████████████████████████████████████████████████▋                      | 51/70 [54:08<23:14, 73.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 74%|████████████████████████████████████████████████████████████▉                     | 52/70 [55:07<20:44, 69.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 76%|██████████████████████████████████████████████████████████████                    | 53/70 [55:58<18:04, 63.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 77%|███████████████████████████████████████████████████████████████▎                  | 54/70 [56:49<15:56, 59.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 79%|████████████████████████████████████████████████████████████████▍                 | 55/70 [57:43<14:33, 58.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|█████████████████████████████████████████████████████████████████▌                | 56/70 [58:37<13:14, 56.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 81%|██████████████████████████████████████████████████████████████████▊               | 57/70 [59:22<11:33, 53.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 83%|██████████████████████████████████████████████████████████████████▎             | 58/70 [1:00:15<10:38, 53.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 84%|███████████████████████████████████████████████████████████████████▍            | 59/70 [1:01:11<09:56, 54.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 86%|████████████████████████████████████████████████████████████████████▌           | 60/70 [1:02:04<08:58, 53.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 87%|█████████████████████████████████████████████████████████████████████▋          | 61/70 [1:03:02<08:14, 54.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 89%|██████████████████████████████████████████████████████████████████████▊         | 62/70 [1:03:58<07:21, 55.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|████████████████████████████████████████████████████████████████████████        | 63/70 [1:04:49<06:17, 53.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 91%|█████████████████████████████████████████████████████████████████████████▏      | 64/70 [1:05:46<05:29, 54.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 93%|██████████████████████████████████████████████████████████████████████████▎     | 65/70 [1:06:40<04:33, 54.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 94%|███████████████████████████████████████████████████████████████████████████▍    | 66/70 [1:07:39<03:44, 56.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 96%|████████████████████████████████████████████████████████████████████████████▌   | 67/70 [1:08:41<02:53, 57.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 97%|█████████████████████████████████████████████████████████████████████████████▋  | 68/70 [1:09:33<01:52, 56.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 99%|██████████████████████████████████████████████████████████████████████████████▊ | 69/70 [1:10:28<00:55, 55.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 70/70 [1:11:21<00:00, 61.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "infected, deceased, quarantine, compliance, violation, ratio, vaccinated = None, None, None, None, None, None, None\n",
    "for i in tqdm(range(1, num_train_iterations + num_eval_iterations + 1)):\n",
    "    deceasedCount = run_simulation(i, True if i > num_train_iterations else False)\n",
    "    print('deceasedCount', deceasedCount)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "be7a1cb9",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu",
   "language": "python",
   "name": "noe"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
