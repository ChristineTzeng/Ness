{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a43748c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prescribed norm: self-quarantine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "906bf94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mesa import Agent, Model\n",
    "from mesa.time import RandomActivation, BaseScheduler\n",
    "from mesa.space import MultiGrid\n",
    "from mesa.datacollection import DataCollector\n",
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "import csv\n",
    "from statistics import mean\n",
    "from pathlib import Path\n",
    "# import tensorflow as tf\n",
    "import pandas as pd\n",
    "from collections import deque\n",
    "import time\n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "16c51d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Simulation Parameters ###\n",
    "\n",
    "file_name = 'message'\n",
    "\n",
    "# general\n",
    "num_train_iterations = 50\n",
    "num_eval_iterations = 20\n",
    "num_steps = 2000\n",
    "num_agents = 100\n",
    "agent_per_home = 1\n",
    "\n",
    "startingState = 0.3\n",
    "vaccine_multiplier = 0.5\n",
    "home_recovery_multiplier = 2\n",
    "\n",
    "num_grocery_stores = 1\n",
    "num_parks = 1\n",
    "\n",
    "FQ_frames = 5\n",
    "\n",
    "# locations\n",
    "HOME = 0\n",
    "PARK = 1\n",
    "GROCERY_STORE = 2\n",
    "HOSPITAL = 3\n",
    "\n",
    "# emotion\n",
    "POSITIVE = 1\n",
    "NEUTRAL = 0\n",
    "NEGATIVE = -1\n",
    "\n",
    "vaccine_last = num_steps#10\n",
    "\n",
    "location_space = [HOME, PARK, GROCERY_STORE, HOSPITAL]\n",
    "\n",
    "NOT_INFECTED = 0\n",
    "INFECTED_A = 1\n",
    "INFECTED_S = 2\n",
    "CRITICAL = 3\n",
    "DECEASED = 4\n",
    "\n",
    "health_space = [NOT_INFECTED, INFECTED_A, INFECTED_S, CRITICAL, DECEASED]\n",
    "\n",
    "evolve_prob = [0.8, 0.36, 0.01, 0.2, 0]\n",
    "recover_prob = [0, 0.2, 0.1, 0.05, 0]\n",
    "\n",
    "#oberve prob\n",
    "N_prob = [0.8,0,0.9,1]\n",
    "A_prob = [0.5,0,1,1]\n",
    "S_prob = [0.3,0,0.9,1]\n",
    "C_prob = [0.1,0,0.4,1]\n",
    "\n",
    "#signal distribution\n",
    "hard_sanctioning_prob = 0.2 #0.2\n",
    "message_sanctioning_prob = 0.36 #0.6\n",
    "emotion_sanctioning_prob = 0.1#1\n",
    "sanction_prob_w_health = [0,0,0.5,0.8]\n",
    "\n",
    "# baseline 2        : prob for sanction 38%\n",
    "# baseline 3 emotion: prob for sanction 20% emotion 12%\n",
    "# baseline 4 message: prob for sanction 20% message(belief reward) 36% \n",
    "# Ness              : prob for sanction 20% emotion(belief reward) 10%\n",
    "\n",
    "# desire/intention\n",
    "stay_home = 0\n",
    "go_outdoors = 1\n",
    "go_shopping = 2\n",
    "\n",
    "intention_space = [stay_home, go_outdoors, go_shopping]\n",
    "\n",
    "# actions\n",
    "MOVE_HOME = 0\n",
    "MOVE_PARK = 1\n",
    "MOVE_STORE = 2\n",
    "MOVE_HOSPITAL = 3\n",
    "\n",
    "action_space = [MOVE_HOME, MOVE_PARK, MOVE_STORE, MOVE_HOSPITAL]\n",
    "sanction_space = ['location', 'health']\n",
    "\n",
    "env_path = ''\n",
    "figure_path = env_path + 'figures/' + file_name + '/'\n",
    "logs_path = env_path + 'logs/' + file_name + '/'\n",
    "\n",
    "lr = 0.001#0.00025\n",
    "gamma = 0.9\n",
    "epsilon_greedy = 0.9\n",
    "epsilon_min = 0.1\n",
    "\n",
    "agent_type_primitive = 1\n",
    "agent_type_sanctioning = 2\n",
    "agent_type_message = 3\n",
    "agent_type_noe = 4\n",
    "agent_type_emotion = 5\n",
    "\n",
    "agent_type = agent_type_message\n",
    "\n",
    "SELF = 0\n",
    "OTHERS = 1\n",
    "\n",
    "# tuples of norms\n",
    "norm = {\n",
    "            \"type\": \"prohibition\",\n",
    "            \"subject\": SELF,\n",
    "            \"object\": OTHERS,\n",
    "            \"antecedent\": {\n",
    "                \"location\": [PARK, GROCERY_STORE, HOSPITAL],\n",
    "                \"attribute\": \"perceived_health\",\n",
    "                \"value\": [INFECTED_S, CRITICAL]\n",
    "            }, \n",
    "            \"consequent\": {\n",
    "                \"emotion\": -0.3, \n",
    "                \"message\": -0.5,\n",
    "                \"hard_sanction\": -1\n",
    "            }\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "73984878",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The basic Q learning model\n",
    "class RL(object):\n",
    "    def __init__(self, actions):\n",
    "        self.actions = actions\n",
    "        self.lr = lr\n",
    "        self.gamma = gamma\n",
    "        self.epsilon_greedy = epsilon_greedy\n",
    "        \n",
    "        self.q_table = pd.DataFrame(columns = self.actions, dtype = np.float64)\n",
    "    \n",
    "    def instantialize(self):\n",
    "        return\n",
    "    \n",
    "    def check_state_exist(self, state):\n",
    "        if state not in self.q_table.index:\n",
    "            self.q_table.loc[state] = pd.Series(\n",
    "                [0] * len(self.actions),\n",
    "                index = self.q_table.columns\n",
    "                )\n",
    "\n",
    "    def action_select(self, state, n_iteration, evaluate):\n",
    "        self.check_state_exist(state)\n",
    "        if evaluate or (np.random.uniform() > 0.9 * (num_train_iterations - n_iteration) / num_train_iterations):\n",
    "            actions= self.q_table.loc[state, :]\n",
    "            action = np.random.choice(actions[actions == np.max(actions)].index)\n",
    "        else:\n",
    "            action = np.random.choice(action_space)\n",
    "        return action\n",
    "    \n",
    "    def getQ(self, state, action):\n",
    "        return self.q_table((state, action), 0.0)\n",
    "\n",
    "class QLearningTable(RL):\n",
    "    def __init__(self, actions):\n",
    "        super(QLearningTable, self).__init__(actions)\n",
    "    \n",
    "    def learn(self, s, a, r, s_):\n",
    "        self.check_state_exist(s_)\n",
    "        q_predict = self.q_table.loc[s, a]\n",
    "        q_target = r + self.gamma * self.q_table.loc[s_, :].max()\n",
    "        # check NaN\n",
    "        q_target = 0 if np.isnan(q_target) else q_target\n",
    "        self.q_table.loc[s, a] += self.lr * (q_target - q_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "185be85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "RL_brain = QLearningTable(actions = list(range(len(action_space))))\n",
    "Sanction_brain = QLearningTable(actions = list(range(len(sanction_space))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a64e9c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HumanAgent(Agent):\n",
    "    \"\"\"The actor in the simulation.\"\"\"\n",
    "    def __init__(self, unique_id, model, evaluate):\n",
    "        super().__init__(unique_id, model)\n",
    "        \n",
    "        self.homeId = unique_id // agent_per_home\n",
    "        self.health = NOT_INFECTED\n",
    "        self.perceived_health = NOT_INFECTED\n",
    "        \n",
    "        self.x = HOME\n",
    "        self.y = unique_id // agent_per_home\n",
    "        \n",
    "        self.infected_times = 0\n",
    "        \n",
    "        self.external_reward = 0\n",
    "        \n",
    "        self.FQ_frames = 0\n",
    "        \n",
    "        self.last_action = None\n",
    "        \n",
    "        self.vaccinated = False\n",
    "        self.vaccine_last = 0\n",
    "        self.intention = 0\n",
    "        self.self_directed_emotion = 0\n",
    "        self.other_directed_emotion = 0\n",
    "        \n",
    "        self.evaluate = evaluate\n",
    "        self.reward = 0\n",
    "        \n",
    "        self.reset_death = False\n",
    "    \n",
    "    def initialize(self):\n",
    "        self.state = self.get_state(0)\n",
    "    \n",
    "    def step(self):\n",
    "        \n",
    "        if self.health != DECEASED:\n",
    "            self.act()\n",
    "        self.updateHealth()\n",
    "    \n",
    "    def get_state(self, env_emotion = None):\n",
    "        loc_x, loc_y = self.pos\n",
    "        return [loc_x, loc_y, self.health, self.intention, self.FQ_frames, self.vaccinated, self.vaccine_last]\n",
    "    # maybe after action\n",
    "    def updateHealth(self):\n",
    "        if self.health == DECEASED:\n",
    "           return\n",
    "\n",
    "        x,y = self.pos\n",
    "        \n",
    "        if self.health in (INFECTED_A, INFECTED_S, CRITICAL):\n",
    "            p = self.random.uniform(0, 1)\n",
    "            ev_prob = evolve_prob[self.health] * (vaccine_multiplier if self.vaccinated else 1)\n",
    "            rec_prob = recover_prob[self.health] * (home_recovery_multiplier if x == HOME else 1)\n",
    "            if p < ev_prob:\n",
    "                self.health += 1\n",
    "            elif p < ev_prob + rec_prob:\n",
    "                self.health = NOT_INFECTED\n",
    "            \n",
    "            if self.health == NOT_INFECTED:\n",
    "                if p < N_prob[NOT_INFECTED]:\n",
    "                    self.perceived_health = NOT_INFECTED\n",
    "                elif p < N_prob[INFECTED_S]:\n",
    "                    self.perceived_health = INFECTED_S\n",
    "                elif p < N_prob[CRITICAL]:\n",
    "                    self.perceived_health = CRITICAL\n",
    "            elif self.health == INFECTED_A:\n",
    "                if p < A_prob[NOT_INFECTED]:\n",
    "                    self.perceived_health = NOT_INFECTED\n",
    "                elif p < A_prob[INFECTED_S]:\n",
    "                    self.perceived_health = INFECTED_S\n",
    "                elif p < A_prob[CRITICAL]:\n",
    "                    self.perceived_health = CRITICAL        \n",
    "            elif self.health == INFECTED_S:\n",
    "                if p < S_prob[NOT_INFECTED]:\n",
    "                    self.perceived_health = NOT_INFECTED\n",
    "                elif p < S_prob[INFECTED_S]:\n",
    "                    self.perceived_health = INFECTED_S\n",
    "                elif p < S_prob[CRITICAL]:\n",
    "                    self.perceived_health = CRITICAL\n",
    "            elif self.health == CRITICAL:\n",
    "                if p < C_prob[NOT_INFECTED]:\n",
    "                    self.perceived_health = NOT_INFECTED\n",
    "                elif p < C_prob[INFECTED_S]:\n",
    "                    self.perceived_health = INFECTED_S\n",
    "                elif p < C_prob[CRITICAL]:\n",
    "                    self.perceived_health = CRITICAL\n",
    "            elif self.health == DECEASED:\n",
    "                self.model.deceasedCount += 1\n",
    "                self.perceived_health = DECEASED\n",
    "                self.reset_death = True\n",
    "                return\n",
    "            \n",
    "            \n",
    "                    \n",
    "        if self.FQ_frames > 0:\n",
    "            self.FQ_frames -= 1\n",
    "        return\n",
    "    \n",
    "    def perceive(self):\n",
    "        x, y = self.pos\n",
    "        return self.model.perceive(x, y, self.unique_id)\n",
    "    \n",
    "    def infect(self, close_contact):\n",
    "        p = self.random.uniform(0, 1)\n",
    "        if self.health == NOT_INFECTED:\n",
    "            if close_contact:\n",
    "                self.health += 1\n",
    "                self.infected_times += 1\n",
    "            else:\n",
    "                # disease proceed with different rate\n",
    "                if p < (evolve_prob[NOT_INFECTED] * vaccine_multiplier) and self.vaccinated:\n",
    "                    self.health += 1\n",
    "                    self.infected_times += 1\n",
    "                elif p < evolve_prob[NOT_INFECTED] and not self.vaccinated:\n",
    "                    self.health += 1\n",
    "                    self.infected_times += 1\n",
    "    \n",
    "    def act(self):\n",
    "        x, y = self.pos\n",
    "        \n",
    "        # action selection\n",
    "        self.intention = np.random.choice(intention_space)\n",
    "        \n",
    "        if self.FQ_frames > 0:\n",
    "            self.last_action = MOVE_HOME\n",
    "            if x != HOME:\n",
    "                self.model.grid.move_agent(self, (HOME, self.unique_id // agent_per_home))\n",
    "                self.x = HOME\n",
    "                self.y = self.unique_id // agent_per_home\n",
    "        else:\n",
    "            action = RL_brain.action_select(str(self.state), self.model.iteration, self.evaluate)\n",
    "            # run action\n",
    "            if action == MOVE_HOME:\n",
    "                self.model.grid.move_agent(self, (HOME, self.unique_id // agent_per_home))\n",
    "                self.x = HOME\n",
    "                self.y = self.unique_id // agent_per_home\n",
    "            elif action == MOVE_STORE:\n",
    "                rd = self.random.randint(0, num_grocery_stores - 1)\n",
    "                self.model.grid.move_agent(self, (GROCERY_STORE, rd))\n",
    "                self.x = GROCERY_STORE\n",
    "                self.y = rd\n",
    "            elif action == MOVE_PARK:\n",
    "                rd = self.random.randint(0, num_parks - 1)\n",
    "                self.model.grid.move_agent(self, (PARK, self.random.randint(0, num_parks - 1)))\n",
    "                self.x = PARK\n",
    "                self.y = rd\n",
    "            elif action == MOVE_HOSPITAL:\n",
    "                self.model.grid.move_agent(self, (HOSPITAL, 0))\n",
    "                self.x = HOSPITAL\n",
    "                self.y = 0\n",
    "                self.vaccinated = True\n",
    "                self.vaccine_last = vaccine_last\n",
    " \n",
    "            self.last_action = action\n",
    "\n",
    "        if agent_type in (agent_type_noe, agent_type_emotion):\n",
    "            self.elicit_emotion(self.intention)\n",
    "    \n",
    "    # elicit self-directed emotion\n",
    "    def elicit_emotion(self, intention):\n",
    "        x, y = self.pos\n",
    "        \n",
    "        # trigger negative emotions while being forced to stay at home\n",
    "        if x == HOME and self.FQ_frames > 0:\n",
    "            self.self_directed_emotion = -1\n",
    "        else:\n",
    "            emotion = (1 if x == intention else -1)\n",
    "            # trigger emotions based on norms\n",
    "            if x != HOME and self.health > 0:\n",
    "                emotion += -1\n",
    "            elif x == HOME and self.health > 0:\n",
    "                emotion += 1\n",
    "    \n",
    "            if emotion == 2: emotion = 1\n",
    "            if emotion == -2: emotion = -1\n",
    "            self.self_directed_emotion = emotion\n",
    "        \n",
    "\n",
    "    def learn(self, force = False):\n",
    "        x, y = self.pos\n",
    "        pre_state = self.state\n",
    "        \n",
    "        self.reward = 0\n",
    "        env_emotion = 0\n",
    "        \n",
    "        if agent_type in (agent_type_noe, agent_type_emotion):\n",
    "            self.state = self.get_state(0)\n",
    "        else:\n",
    "            self.state = self.get_state(0)\n",
    "        \n",
    "        if self.health == DECEASED and not self.reset_death:\n",
    "            if self.x != HOME or self.x != -1:\n",
    "                self.model.grid.move_agent(self, (HOME, self.unique_id // agent_per_home))\n",
    "                self.x = HOME\n",
    "                self.y = self.unique_id // agent_per_home\n",
    "            self.reward, self.FQ_frames = 0, 0\n",
    "            self.self_directed_emotion, self.other_directed_emotion = 0, 0\n",
    "            self.intention, self.last_action, self.x, self.y = -1, -1, -1, -1\n",
    "            return\n",
    "        \n",
    "        reward = -2 if self.health == DECEASED else 0\n",
    "        \n",
    "        if self.FQ_frames > 0:\n",
    "            reward -= 1\n",
    "        \n",
    "        reward += 1 if self.intention == x else -1\n",
    "        \n",
    "        if agent_type in (agent_type_noe, agent_type_emotion):\n",
    "            reward += (self.self_directed_emotion + self.other_directed_emotion)\n",
    "        \n",
    "        reward += self.external_reward\n",
    "        \n",
    "        self.reward = reward\n",
    "        \n",
    "        self.reset_death = False\n",
    "        self.external_reward = 0\n",
    "        \n",
    "        if self.evaluate:\n",
    "            return\n",
    "        \n",
    "        RL_brain.learn(str(pre_state), self.last_action, reward, str(self.state))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8fe18820",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimulationModel(Model):\n",
    "    \"\"\"The model runs the simulation.\"\"\"\n",
    "    def __init__(self, N, iteration, evaluate):\n",
    "        self.num_agents = N\n",
    "        self.random.seed(1)\n",
    "        self.evaluate = evaluate\n",
    "        \n",
    "        self.grid = MultiGrid(5, num_agents // agent_per_home, False)\n",
    "        self.schedule = RandomActivation(self)\n",
    "        self.iteration = iteration\n",
    "        \n",
    "        self.deceasedCount = 0\n",
    "        \n",
    "        self.datacollector = DataCollector(\n",
    "            model_reporters={\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        self.reset()\n",
    "    \n",
    "    def reset(self):\n",
    "        if self.schedule.get_agent_count() > 0:\n",
    "            for agent in self.schedule.agents:\n",
    "                self.schedule.remove(agent)\n",
    "        # load agents\n",
    "        for i in range(self.num_agents):\n",
    "            a = HumanAgent(i, self, self.evaluate)\n",
    "            self.schedule.add(a)\n",
    "            self.grid.place_agent(a, (HOME, 0))\n",
    "        \n",
    "        for a in self.random.sample(self.schedule.agents, int(startingState * self.num_agents)):\n",
    "            a.health = INFECTED_A\n",
    "            a.infected_times += 1\n",
    "        \n",
    "        for agent in self.schedule.agents:\n",
    "            agent.initialize()\n",
    "        \n",
    "        self.deceased_count = 0\n",
    "        self.violation_count = 0\n",
    "        self.compliance_count = 0\n",
    "        self.cumulative_deceased = 0\n",
    "        self.cumulative_violation = 0\n",
    "        self.cumulative_compliance = 0\n",
    "    \n",
    "    def run_norms(self):\n",
    "        emotion_saction_set, message_sanction_set, hard_saction_set = set(), set(), set()\n",
    "        # Home\n",
    "        for y in range(num_agents // agent_per_home):\n",
    "            agents = self.grid.get_cell_list_contents([(HOME,y)])\n",
    "            comply_agents = [agent for agent in agents if agent.health != DECEASED and agent.perceived_health != NOT_INFECTED and agent.FQ_frames == 0 ]\n",
    "            for agent in comply_agents:\n",
    "                agent.external_reward -= norm.get(\"consequent\").get(\"hard_sanction\")\n",
    "                if agent_type in (agent_type_emotion, agent_type_noe):\n",
    "                    agent.other_directed_emotion = 1\n",
    "        # Park\n",
    "        if PARK in norm.get(\"antecedent\").get(\"location\"):\n",
    "            for y in range(num_parks):\n",
    "                agents = self.grid.get_cell_list_contents([(PARK,y)])\n",
    "                agents = [agent for agent in agents if agent.health != DECEASED ]\n",
    "                violate_agents = [agent for agent in agents if getattr(agent, norm.get(\"antecedent\").get(\"attribute\")) in norm.get(\"antecedent\").get(\"value\") ]\n",
    "                \n",
    "                if len(agents) - len(violate_agents) > 0:\n",
    "                    for agent in violate_agents:\n",
    "                        sanctioners = [sanctioner for sanctioner in agents if sanctioner.health == NOT_INFECTED and sanctioner.unique_id != agent.unique_id]    \n",
    "\n",
    "                        hard_sanction, sanction = False, False\n",
    "                        p = self.random.uniform(0, 1)\n",
    "                        if p < sanction_prob_w_health[agent.perceived_health]:\n",
    "                            p = self.random.uniform(0, 1)\n",
    "                            if p < hard_sanctioning_prob:\n",
    "                                agent.FQ_frames = FQ_frames\n",
    "                                hard_sanction = True\n",
    "                            \n",
    "                            elif agent_type == agent_type_message:\n",
    "                                if p < message_sanctioning_prob:\n",
    "                                    sanction = True\n",
    "                                    agent.external_reward += norm.get(\"consequent\").get(\"message\")\n",
    "                            elif agent_type in (agent_type_emotion, agent_type_noe):\n",
    "                                if p < emotion_sanctioning_prob:\n",
    "                                    sanction = True\n",
    "                                    if agent_type == agent_type_emotion:\n",
    "                                        agent.external_reward += norm.get(\"consequent\").get(\"emotion\")\n",
    "                                    agent.other_directed_emotion = -1\n",
    "\n",
    "                        if agent_type in (agent_type_emotion, agent_type_noe) and sanction:\n",
    "                            for sanctioner in sanctioners:\n",
    "                                if sanctioner.unique_id not in emotion_saction_set:\n",
    "                                    emotion_saction_set.add(sanctioner.unique_id)\n",
    "                                    sanctioner.other_directed_emotion = 0\n",
    "\n",
    "        # Grocery\n",
    "        if GROCERY_STORE in norm.get(\"antecedent\").get(\"location\"):\n",
    "            for y in range(num_grocery_stores):\n",
    "                agents = self.grid.get_cell_list_contents([(GROCERY_STORE,y)])\n",
    "                agents = [agent for agent in agents if agent.health != DECEASED ]\n",
    "                violate_agents = [agent for agent in agents if getattr(agent, norm.get(\"antecedent\").get(\"attribute\")) in norm.get(\"antecedent\").get(\"value\") ]\n",
    "                \n",
    "                if len(agents) - len(violate_agents) > 0:\n",
    "                    for agent in violate_agents:\n",
    "                        sanctioners = [sanctioner for sanctioner in agents if sanctioner.health == NOT_INFECTED and sanctioner.unique_id != agent.unique_id]    \n",
    "                        \n",
    "                        hard_sanction, sanction = False, False\n",
    "                        p = self.random.uniform(0, 1)\n",
    "                        if p < sanction_prob_w_health[agent.perceived_health]:\n",
    "                            p = self.random.uniform(0, 1)\n",
    "                            if p < hard_sanctioning_prob:\n",
    "                                agent.FQ_frames = FQ_frames\n",
    "                                hard_sanction = True\n",
    "                            \n",
    "                            elif agent_type == agent_type_message:\n",
    "                                if p < message_sanctioning_prob:\n",
    "                                    sanction = True\n",
    "                                    agent.external_reward += norm.get(\"consequent\").get(\"message\")\n",
    "                            elif agent_type in (agent_type_emotion, agent_type_noe):\n",
    "                                if p < emotion_sanctioning_prob:\n",
    "                                    sanction = True\n",
    "                                    if agent_type == agent_type_emotion:\n",
    "                                        agent.external_reward += norm.get(\"consequent\").get(\"emotion\")\n",
    "                                    agent.other_directed_emotion = -1\n",
    "\n",
    "                        if agent_type in (agent_type_emotion, agent_type_noe) and sanction:\n",
    "                            for sanctioner in sanctioners:\n",
    "                                if sanctioner.unique_id not in emotion_saction_set:\n",
    "                                    emotion_saction_set.add(sanctioner.unique_id)\n",
    "                                    sanctioner.other_directed_emotion = 0\n",
    "\n",
    "            \n",
    "        if HOSPITAL in norm.get(\"antecedent\").get(\"location\"):\n",
    "            agents = self.grid.get_cell_list_contents([(HOSPITAL,0)])\n",
    "            agents = [agent for agent in agents if agent.health != DECEASED ]\n",
    "            violate_agents = [agent for agent in agents if getattr(agent, norm.get(\"antecedent\").get(\"attribute\")) in norm.get(\"antecedent\").get(\"value\") ]\n",
    "            \n",
    "            if len(agents) - len(violate_agents) > 0:\n",
    "                for agent in violate_agents:\n",
    "                    sanctioners = [sanctioner for sanctioner in agents if sanctioner.health == NOT_INFECTED and sanctioner.unique_id != agent.unique_id]\n",
    "                    \n",
    "                    hard_sanction, sanction = False, False\n",
    "                    p = self.random.uniform(0, 1)\n",
    "                    if p < sanction_prob_w_health[agent.perceived_health]:\n",
    "                        p = self.random.uniform(0, 1)\n",
    "                        if p < hard_sanctioning_prob:\n",
    "                            agent.FQ_frames = FQ_frames\n",
    "                            hard_sanction = True\n",
    "                            \n",
    "                        elif agent_type == agent_type_message:\n",
    "                            if p < message_sanctioning_prob:\n",
    "                                sanction = True\n",
    "                                agent.external_reward += norm.get(\"consequent\").get(\"message\")\n",
    "                        elif agent_type in (agent_type_emotion, agent_type_noe):\n",
    "                            if p < emotion_sanctioning_prob:\n",
    "                                sanction = True\n",
    "                                if agent_type == agent_type_emotion:\n",
    "                                    agent.external_reward += norm.get(\"consequent\").get(\"emotion\")\n",
    "                                agent.other_directed_emotion = -1\n",
    "\n",
    "#                     if hard_sanction and agent.health == NOT_INFECTED:\n",
    "#                         for sanctioner in sanctioners:\n",
    "#                             if sanctioner.unique_id not in hard_saction_set:\n",
    "#                                 hard_saction_set.add(sanctioner.unique_id)\n",
    "#                                 sanctioner.other_directed_emotion = -1\n",
    "#                                 sanctioner.external_reward += norm.get(\"consequent\").get(\"hard_sanction\")\n",
    "#                                 if agent.health == NOT_INFECTED:\n",
    "#                                     sanctioner.external_reward += norm.get(\"consequent\").get(\"hard_sanction\")\n",
    "                    \n",
    "                    # less penalty for wrong accuse of message; no penalty for emotion\n",
    "#                     if agent_type == agent_type_message and sanction:\n",
    "#                         for sanctioner in sanctioners:\n",
    "#                             if sanctioner.unique_id not in message_sanction_set:\n",
    "#                                 message_sanction_set.add(sanctioner.unique_id)\n",
    "#                                 sanctioner.other_directed_emotion = -1\n",
    "#                                 sanctioner.external_reward += norm.get(\"consequent\").get(\"message\")\n",
    "#                                 if agent.health == NOT_INFECTED:\n",
    "#                                     sanctioner.external_reward += norm.get(\"consequent\").get(\"message\")\n",
    "                \n",
    "                    if agent_type in (agent_type_emotion, agent_type_noe) and sanction:\n",
    "                        for sanctioner in sanctioners:\n",
    "                            if sanctioner.unique_id not in emotion_saction_set:\n",
    "                                emotion_saction_set.add(sanctioner.unique_id)\n",
    "                                sanctioner.other_directed_emotion = 0\n",
    "\n",
    "    def perceive(self, x, y, agent_id):\n",
    "        agents = self.grid.get_cell_list_contents([(x, y)])\n",
    "        emotions = [agent.other_directed_emotion for agent in agents if agent.unique_id != agent_id]\n",
    "        return sum(emotions)/len(emotions) if len(emotions) > 0 else 0\n",
    "    \n",
    "    def learn(self):\n",
    "        for i in range(self.num_agents):\n",
    "            agent = self.schedule._agents[i]\n",
    "            agent.learn()\n",
    "    \n",
    "    def compute_infected(self):\n",
    "        infectedAgents = [agent for agent in self.schedule.agents if agent.health in (INFECTED_A, INFECTED_S, CRITICAL) ]\n",
    "        return len(infectedAgents)\n",
    "    \n",
    "    def compute_deceased(self):\n",
    "        deceasedAgents = [agent for agent in self.schedule.agents if agent.health == DECEASED ]\n",
    "        return len(deceasedAgents)\n",
    "    \n",
    "    def compute_compliance(self):\n",
    "        agents = [agent for agent in self.schedule.agents if agent.last_action == MOVE_HOME and agent.health not in (NOT_INFECTED, DECEASED) ]\n",
    "        return len(agents)\n",
    "    \n",
    "    def compute_violation(self):\n",
    "        agents = [agent for agent in self.schedule.agents if agent.last_action != MOVE_HOME and agent.health not in (NOT_INFECTED, DECEASED) ]\n",
    "        return len(agents)\n",
    "    \n",
    "    def compute_compliance_rate(self):\n",
    "        comp = self.compute_compliance()\n",
    "        vio = self.compute_violation()\n",
    "        return comp / (comp + vio) if comp + vio > 0 else 0\n",
    "    \n",
    "    def compute_vaccinated(self):\n",
    "        agents = [agent for agent in self.schedule.agents if agent.vaccinated and agent.health != DECEASED ]\n",
    "        return len(agents)\n",
    "    \n",
    "    def compute_QC(self):\n",
    "        count = 0\n",
    "        for y in range(num_agents // agent_per_home):\n",
    "            agents = self.grid.get_cell_list_contents([(HOME,y)])\n",
    "            count += len(agents)\n",
    "        return count\n",
    "    \n",
    "    def compute_FQ(self):\n",
    "        count = 0\n",
    "        for y in range(num_agents // agent_per_home):\n",
    "            agents = self.grid.get_cell_list_contents([(HOME,y)])\n",
    "            agents = [agent for agent in agents if agent.FQ_frames > 1]\n",
    "            count += len(agents)\n",
    "        return count\n",
    "    \n",
    "    def step(self):\n",
    "        self.schedule.step()\n",
    "        if agent_type != agent_type_primitive:\n",
    "            self.run_norms()\n",
    "        self.identifyAgentsAndUpdateSpread()\n",
    "        self.learn()\n",
    "        self.write_csv()\n",
    "        self.datacollector.collect(self)\n",
    "        self.decay_emotion()\n",
    "    \n",
    "    def decay_emotion(self):\n",
    "        for i in range(self.num_agents):\n",
    "            agent = self.schedule._agents[i]\n",
    "            agent.other_directed_emotion = 0\n",
    "            agent.self_directed_emotion = 0\n",
    "\n",
    "    def write_csv(self):\n",
    "        if self.iteration <= num_train_iterations:\n",
    "            return\n",
    "        \n",
    "        with open(logs_path + file_name + '_agent.csv', 'a', newline = '') as agent_file:\n",
    "            writer = csv.writer(agent_file, delimiter = ',')\n",
    "            for i in range(self.num_agents):\n",
    "                agent = self.schedule._agents[i]\n",
    "                if agent_type in (agent_type_primitive, agent_type_sanctioning):\n",
    "                    writer.writerow([self.iteration, self.schedule.steps, agent.unique_id, agent.health, agent.infected_times, agent.reward, agent.FQ_frames, agent.vaccinated, agent.vaccine_last, agent.intention, agent.last_action, agent.x, agent.y, agent.self_directed_emotion, agent.other_directed_emotion])\n",
    "                elif agent_type == agent_type_message:\n",
    "                    writer.writerow([self.iteration, self.schedule.steps, agent.unique_id, agent.health, agent.infected_times, agent.reward, agent.FQ_frames, agent.vaccinated, agent.vaccine_last, agent.intention, agent.last_action, agent.x, agent.y, agent.self_directed_emotion, agent.other_directed_emotion])\n",
    "                elif agent_type == agent_type_noe:\n",
    "                    writer.writerow([self.iteration, self.schedule.steps, agent.unique_id, agent.health, agent.infected_times, agent.reward, agent.FQ_frames, agent.vaccinated, agent.vaccine_last, agent.intention, agent.last_action, agent.x, agent.y, agent.self_directed_emotion, agent.other_directed_emotion])\n",
    "                else:\n",
    "                    writer.writerow([self.iteration, self.schedule.steps, agent.unique_id, agent.health, agent.infected_times, agent.reward, agent.FQ_frames, agent.vaccinated, agent.vaccine_last, agent.intention, agent.last_action, agent.x, agent.y, agent.self_directed_emotion, agent.other_directed_emotion])\n",
    "        agent_file.close()\n",
    "    \n",
    "    def identifyAgentsAndUpdateSpread(self):\n",
    "        # Park\n",
    "        for y in range(num_parks):\n",
    "            agents = self.grid.get_cell_list_contents([(PARK,y)])\n",
    "            self.updateSpread(agents)\n",
    "        # Grocery\n",
    "        for y in range(num_grocery_stores):\n",
    "            agents = self.grid.get_cell_list_contents([(GROCERY_STORE,y)])\n",
    "            self.updateSpread(agents)\n",
    "        # Home\n",
    "        for y in range(num_agents // agent_per_home):\n",
    "            agents = self.grid.get_cell_list_contents([(HOME,y)])\n",
    "            self.updateSpread(agents, True)\n",
    "    def updateSpread(self, agents, close_contact = False):\n",
    "        if any(a.health in (INFECTED_A, INFECTED_S, CRITICAL) for a in agents):\n",
    "            [a.infect(close_contact) for a in agents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "60c38d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_simulation(iteration, evaluate):\n",
    "    model = SimulationModel(num_agents, iteration, evaluate)\n",
    "    for i in range(num_steps):\n",
    "        model.step()\n",
    "    modelDF = model.datacollector.get_model_vars_dataframe()\n",
    "    return model.deceasedCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "30f9cedb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|█▏                                                                               | 1/70 [00:57<1:06:06, 57.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|██▎                                                                              | 2/70 [01:49<1:01:31, 54.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|███▍                                                                             | 3/70 [02:45<1:01:27, 55.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|████▋                                                                            | 4/70 [03:44<1:02:27, 56.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|█████▊                                                                           | 5/70 [04:40<1:00:57, 56.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  9%|██████▉                                                                          | 6/70 [05:43<1:02:41, 58.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|████████                                                                         | 7/70 [06:47<1:03:12, 60.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 11%|█████████▎                                                                       | 8/70 [07:50<1:03:09, 61.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 13%|██████████▍                                                                      | 9/70 [08:49<1:01:34, 60.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 14%|███████████▍                                                                    | 10/70 [09:59<1:03:31, 63.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|████████████▌                                                                   | 11/70 [11:07<1:03:43, 64.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|█████████████▋                                                                  | 12/70 [12:16<1:04:00, 66.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 19%|██████████████▊                                                                 | 13/70 [13:22<1:02:38, 65.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|████████████████                                                                | 14/70 [14:26<1:01:10, 65.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 21%|█████████████████▏                                                              | 15/70 [15:36<1:01:22, 66.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 23%|██████████████████▎                                                             | 16/70 [16:47<1:01:12, 68.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|███████████████████▍                                                            | 17/70 [18:05<1:02:41, 70.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 26%|████████████████████▌                                                           | 18/70 [19:19<1:02:22, 71.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 27%|█████████████████████▋                                                          | 19/70 [20:39<1:03:20, 74.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 29%|██████████████████████▊                                                         | 20/70 [22:03<1:04:27, 77.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|████████████████████████                                                        | 21/70 [23:20<1:02:55, 77.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 31%|█████████████████████████▏                                                      | 22/70 [24:46<1:03:46, 79.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|██████████████████████████▎                                                     | 23/70 [26:13<1:04:19, 82.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 34%|███████████████████████████▍                                                    | 24/70 [27:40<1:03:54, 83.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 36%|████████████████████████████▌                                                   | 25/70 [29:03<1:02:32, 83.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 37%|█████████████████████████████▋                                                  | 26/70 [30:38<1:03:44, 86.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 39%|██████████████████████████████▊                                                 | 27/70 [32:08<1:02:52, 87.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████████████████████████████████                                                | 28/70 [33:39<1:02:03, 88.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 41%|█████████████████████████████████▏                                              | 29/70 [35:12<1:01:33, 90.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 43%|██████████████████████████████████▎                                             | 30/70 [36:55<1:02:39, 94.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 44%|███████████████████████████████████▍                                            | 31/70 [38:35<1:02:17, 95.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 46%|████████████████████████████████████▌                                           | 32/70 [40:15<1:01:19, 96.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 47%|█████████████████████████████████████▋                                          | 33/70 [41:59<1:01:03, 99.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 49%|██████████████████████████████████████▎                                        | 34/70 [43:45<1:00:48, 101.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|███████████████████████████████████████▌                                       | 35/70 [45:42<1:01:43, 105.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 51%|████████████████████████████████████████▋                                      | 36/70 [47:38<1:01:45, 108.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 53%|█████████████████████████████████████████▊                                     | 37/70 [49:43<1:02:33, 113.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 54%|██████████████████████████████████████████▉                                    | 38/70 [51:48<1:02:29, 117.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 56%|████████████████████████████████████████████                                   | 39/70 [54:08<1:03:59, 123.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 57%|█████████████████████████████████████████████▏                                 | 40/70 [56:37<1:05:43, 131.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 59%|██████████████████████████████████████████████▎                                | 41/70 [59:07<1:06:14, 137.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████████████████████████████████████████████▏                              | 42/70 [1:01:34<1:05:24, 140.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 61%|███████████████████████████████████████████████▎                             | 43/70 [1:04:05<1:04:30, 143.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 63%|████████████████████████████████████████████████▍                            | 44/70 [1:06:44<1:04:10, 148.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 64%|█████████████████████████████████████████████████▌                           | 45/70 [1:09:18<1:02:23, 149.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 66%|██████████████████████████████████████████████████▌                          | 46/70 [1:11:56<1:00:54, 152.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|█████████████████████████████████████████████████████                          | 47/70 [1:14:30<58:31, 152.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 69%|██████████████████████████████████████████████████████▏                        | 48/70 [1:17:07<56:27, 153.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|███████████████████████████████████████████████████████▎                       | 49/70 [1:19:45<54:18, 155.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 71%|████████████████████████████████████████████████████████▍                      | 50/70 [1:22:32<52:55, 158.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 73%|█████████████████████████████████████████████████████████▌                     | 51/70 [1:23:58<43:21, 136.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 74%|██████████████████████████████████████████████████████████▋                    | 52/70 [1:25:32<37:13, 124.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 76%|███████████████████████████████████████████████████████████▊                   | 53/70 [1:26:58<31:56, 112.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 77%|████████████████████████████████████████████████████████████▉                  | 54/70 [1:28:25<27:59, 104.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 79%|██████████████████████████████████████████████████████████████                 | 55/70 [1:29:55<25:06, 100.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████████████████████████████████████████████████████████████                | 56/70 [1:31:16<22:07, 94.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 81%|█████████████████████████████████████████████████████████████████▏              | 57/70 [1:32:36<19:34, 90.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 83%|██████████████████████████████████████████████████████████████████▎             | 58/70 [1:33:56<17:24, 87.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 84%|███████████████████████████████████████████████████████████████████▍            | 59/70 [1:35:23<15:57, 87.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 86%|████████████████████████████████████████████████████████████████████▌           | 60/70 [1:36:44<14:14, 85.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 87%|█████████████████████████████████████████████████████████████████████▋          | 61/70 [1:38:05<12:37, 84.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 89%|██████████████████████████████████████████████████████████████████████▊         | 62/70 [1:39:22<10:55, 81.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|████████████████████████████████████████████████████████████████████████        | 63/70 [1:40:44<09:33, 81.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 91%|█████████████████████████████████████████████████████████████████████████▏      | 64/70 [1:41:59<07:58, 79.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 93%|██████████████████████████████████████████████████████████████████████████▎     | 65/70 [1:43:10<06:25, 77.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 94%|███████████████████████████████████████████████████████████████████████████▍    | 66/70 [1:44:33<05:16, 79.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 96%|████████████████████████████████████████████████████████████████████████████▌   | 67/70 [1:45:59<04:03, 81.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 97%|█████████████████████████████████████████████████████████████████████████████▋  | 68/70 [1:47:27<02:46, 83.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 99%|██████████████████████████████████████████████████████████████████████████████▊ | 69/70 [1:48:46<01:21, 81.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 70/70 [1:50:09<00:00, 94.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "infected, deceased, quarantine, compliance, violation, ratio, vaccinated = None, None, None, None, None, None, None\n",
    "for i in tqdm(range(1, num_train_iterations + num_eval_iterations + 1)):\n",
    "    deceasedCount = run_simulation(i, True if i > num_train_iterations else False)\n",
    "    print('deceasedCount', deceasedCount)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu",
   "language": "python",
   "name": "noe"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
