{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a43748c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prescriptive norm: forced-quarantine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "906bf94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mesa import Agent, Model\n",
    "from mesa.time import RandomActivation, BaseScheduler\n",
    "from mesa.space import MultiGrid\n",
    "from mesa.datacollection import DataCollector\n",
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "import csv\n",
    "from statistics import mean\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from collections import deque\n",
    "import time\n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16c51d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Simulation Parameters ###\n",
    "\n",
    "file_name = 'hint_prob'\n",
    "\n",
    "# general\n",
    "num_train_iterations = 50\n",
    "num_eval_iterations = 20\n",
    "num_steps = 2000\n",
    "num_agents = 100\n",
    "agent_per_home = 1\n",
    "\n",
    "startingState = 0.3\n",
    "vaccine_multiplier = 0.5\n",
    "home_recovery_multiplier = 2\n",
    "\n",
    "num_grocery_stores = 1\n",
    "num_parks = 1\n",
    "\n",
    "FQ_frames = 5\n",
    "\n",
    "# locations\n",
    "HOME = 0\n",
    "PARK = 1\n",
    "GROCERY_STORE = 2\n",
    "HOSPITAL = 3\n",
    "\n",
    "# emotion\n",
    "POSITIVE = 1\n",
    "NEUTRAL = 0\n",
    "NEGATIVE = -1\n",
    "\n",
    "vaccine_last = num_steps#10\n",
    "\n",
    "location_space = [HOME, PARK, GROCERY_STORE, HOSPITAL]\n",
    "\n",
    "NOT_INFECTED = 0\n",
    "INFECTED_A = 1\n",
    "INFECTED_S = 2\n",
    "CRITICAL = 3\n",
    "DECEASED = 4\n",
    "\n",
    "health_space = [NOT_INFECTED, INFECTED_A, INFECTED_S, CRITICAL, DECEASED]\n",
    "\n",
    "evolve_prob = [0.8, 0.36, 0.01, 0.2, 0]\n",
    "recover_prob = [0, 0.2, 0.1, 0.05, 0]\n",
    "\n",
    "#oberve prob\n",
    "N_prob = [0.8,0,0.9,1]\n",
    "A_prob = [0.5,0,1,1]\n",
    "S_prob = [0.3,0,0.9,1]\n",
    "C_prob = [0.1,0,0.4,1]\n",
    "\n",
    "# trial distribution\n",
    "# N_prob = [0.6,0.8,0.9,1]\n",
    "# A_prob = [0.4,0.6,1,1]\n",
    "# S_prob = [0.2,0.4,0.9,1]\n",
    "# C_prob = [0.1,0.2,0.4,1]\n",
    "\n",
    "#signal distribution\n",
    "hard_sanctioning_prob = 0.20 #0.2\n",
    "message_sanctioning_prob = 0.0#0.6\n",
    "emotion_sanctioning_prob = 0.38#1\n",
    "sanction_prob_w_health = [0,0,0.5,0.8]\n",
    "\n",
    "# message_prob: prob for sanction 20% message(belief reward) 38% \n",
    "# emote_prob: prob for sanction 20% emotion 38%\n",
    "# hint_prob: prob for sanction 20% emotion 38%\n",
    "# hint_balance: prob for sanction 20% emotion 38%\n",
    "\n",
    "# sanction_weighted: prob for sanction 28%\n",
    "# message_weighted: prob for sanction 20% message 16% \n",
    "# feeling_weighted: prob for sanction 20% emotion 16%\n",
    "# hint_weighted: prob for sanction 20% emotion 10%   -> 10 * 0.5 + 10 * 0.3\n",
    " \n",
    "# desire/intention\n",
    "stay_home = 0\n",
    "go_outdoors = 1\n",
    "go_shopping = 2\n",
    "\n",
    "intention_space = [stay_home, go_outdoors, go_shopping]\n",
    "\n",
    "# actions\n",
    "MOVE_HOME = 0\n",
    "MOVE_PARK = 1\n",
    "MOVE_STORE = 2\n",
    "MOVE_HOSPITAL = 3\n",
    "\n",
    "action_space = [MOVE_HOME, MOVE_PARK, MOVE_STORE, MOVE_HOSPITAL]\n",
    "sanction_space = ['location', 'health']\n",
    "\n",
    "env_path = ''\n",
    "figure_path = env_path + 'figures/' + file_name + '/'\n",
    "logs_path = env_path + 'logs/' + file_name + '/'\n",
    "\n",
    "lr = 0.001#0.00025\n",
    "gamma = 0.9\n",
    "epsilon_greedy = 0.9\n",
    "epsilon_min = 0.1\n",
    "\n",
    "agent_type_primitive = 1\n",
    "agent_type_sanctioning = 2\n",
    "agent_type_message = 3\n",
    "agent_type_emote = 4\n",
    "agent_type_hint = 5\n",
    "\n",
    "agent_type = agent_type_hint\n",
    "\n",
    "SELF = 0\n",
    "OTHERS = 1\n",
    "\n",
    "sanction_payoff = 1.0\n",
    "emotion_payoff = 0.5\n",
    "\n",
    "# tuples of norms\n",
    "norm = {\n",
    "            \"type\": \"prohibition\",\n",
    "            \"subject\": SELF,\n",
    "            \"object\": OTHERS,\n",
    "            \"antecedent\": {\n",
    "                \"location\": [PARK, GROCERY_STORE, HOSPITAL],\n",
    "                \"attribute\": \"perceived_health\",\n",
    "                \"value\": [INFECTED_S, CRITICAL]\n",
    "            }, \n",
    "            \"consequent\": {\n",
    "                \"emotion\": -0.3, \n",
    "                \"message\": -0.5,\n",
    "                \"hard_sanction\": -1\n",
    "            }\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73984878",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The basic Q learning model\n",
    "class RL(object):\n",
    "    def __init__(self, actions):\n",
    "        self.actions = actions\n",
    "        self.lr = lr\n",
    "        self.gamma = gamma\n",
    "        self.epsilon_greedy = epsilon_greedy\n",
    "        \n",
    "        self.q_table = pd.DataFrame(columns = self.actions, dtype = np.float64)\n",
    "    \n",
    "    def instantialize(self):\n",
    "        return\n",
    "    \n",
    "    def check_state_exist(self, state):\n",
    "        if state not in self.q_table.index:\n",
    "            self.q_table.loc[state] = pd.Series(\n",
    "                [0] * len(self.actions),\n",
    "                index = self.q_table.columns\n",
    "                )\n",
    "\n",
    "    def action_select(self, state, n_iteration, evaluate):\n",
    "        self.check_state_exist(state)\n",
    "        if evaluate or (np.random.uniform() > 0.9 * (num_train_iterations - n_iteration) / num_train_iterations):\n",
    "            actions= self.q_table.loc[state, :]\n",
    "            action = np.random.choice(actions[actions == np.max(actions)].index)\n",
    "        else:\n",
    "            action = np.random.choice(action_space)\n",
    "        return action\n",
    "    \n",
    "    def getQ(self, state, action):\n",
    "        return self.q_table((state, action), 0.0)\n",
    "\n",
    "class QLearningTable(RL):\n",
    "    def __init__(self, actions):\n",
    "        super(QLearningTable, self).__init__(actions)\n",
    "    \n",
    "    def learn(self, s, a, r, s_):\n",
    "        self.check_state_exist(s_)\n",
    "        q_predict = self.q_table.loc[s, a]\n",
    "        q_target = r + self.gamma * self.q_table.loc[s_, :].max()\n",
    "        # check NaN\n",
    "        q_target = 0 if np.isnan(q_target) else q_target\n",
    "        self.q_table.loc[s, a] += self.lr * (q_target - q_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "185be85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "RL_brain = QLearningTable(actions = list(range(len(action_space))))\n",
    "Sanction_brain = QLearningTable(actions = list(range(len(sanction_space))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a64e9c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HumanAgent(Agent):\n",
    "    \"\"\"The actor in the simulation.\"\"\"\n",
    "    def __init__(self, unique_id, model, evaluate):\n",
    "        super().__init__(unique_id, model)\n",
    "        \n",
    "        self.homeId = unique_id // agent_per_home\n",
    "        self.health = NOT_INFECTED\n",
    "        self.perceived_health = NOT_INFECTED\n",
    "        \n",
    "        self.x = HOME\n",
    "        self.y = unique_id // agent_per_home\n",
    "        \n",
    "        self.infected_times = 0\n",
    "        \n",
    "        self.external_reward = 0\n",
    "        \n",
    "        self.FQ_frames = 0\n",
    "        \n",
    "        self.last_action = None\n",
    "        \n",
    "        self.vaccinated = False\n",
    "        self.vaccine_last = 0\n",
    "        self.intention = 0\n",
    "        self.self_directed_emotion = 0\n",
    "        self.other_directed_emotion = 0\n",
    "        \n",
    "        self.evaluate = evaluate\n",
    "        self.reward = 0\n",
    "        \n",
    "        self.reset_death = False\n",
    "    \n",
    "    def initialize(self):\n",
    "        self.state = self.get_state(0)\n",
    "    \n",
    "    def step(self):\n",
    "        \n",
    "        if self.health != DECEASED:\n",
    "            self.act()\n",
    "        self.updateHealth()\n",
    "    \n",
    "    # observation\n",
    "    def get_state(self, env_emotion = None):\n",
    "        loc_x, loc_y = self.pos\n",
    "        return [loc_x, loc_y, self.health, self.intention, self.FQ_frames, self.vaccinated, self.vaccine_last]\n",
    "    \n",
    "    # symptom progress\n",
    "    def updateHealth(self):\n",
    "        if self.health == DECEASED:\n",
    "           return\n",
    "\n",
    "        x,y = self.pos\n",
    "        \n",
    "        if self.health in (INFECTED_A, INFECTED_S, CRITICAL):\n",
    "            p = self.random.uniform(0, 1)\n",
    "            ev_prob = evolve_prob[self.health] * (vaccine_multiplier if self.vaccinated else 1)\n",
    "            rec_prob = recover_prob[self.health] * (home_recovery_multiplier if x == HOME else 1)\n",
    "            if p < ev_prob:\n",
    "                self.health += 1\n",
    "            elif p < ev_prob + rec_prob:\n",
    "                self.health = NOT_INFECTED\n",
    "            \n",
    "            if self.health == NOT_INFECTED:\n",
    "                if p < N_prob[NOT_INFECTED]:\n",
    "                    self.perceived_health = NOT_INFECTED\n",
    "                elif p < N_prob[INFECTED_A]:\n",
    "                    self.perceived_health = INFECTED_A\n",
    "                elif p < N_prob[INFECTED_S]:\n",
    "                    self.perceived_health = INFECTED_S\n",
    "                elif p < N_prob[CRITICAL]:\n",
    "                    self.perceived_health = CRITICAL\n",
    "            elif self.health == INFECTED_A:\n",
    "                if p < A_prob[NOT_INFECTED]:\n",
    "                    self.perceived_health = NOT_INFECTED\n",
    "                elif p < A_prob[INFECTED_A]:\n",
    "                    self.perceived_health = INFECTED_A\n",
    "                elif p < A_prob[INFECTED_S]:\n",
    "                    self.perceived_health = INFECTED_S\n",
    "                elif p < A_prob[CRITICAL]:\n",
    "                    self.perceived_health = CRITICAL        \n",
    "            elif self.health == INFECTED_S:\n",
    "                if p < S_prob[NOT_INFECTED]:\n",
    "                    self.perceived_health = NOT_INFECTED\n",
    "                elif p < S_prob[INFECTED_A]:\n",
    "                    self.perceived_health = INFECTED_A\n",
    "                elif p < S_prob[INFECTED_S]:\n",
    "                    self.perceived_health = INFECTED_S\n",
    "                elif p < S_prob[CRITICAL]:\n",
    "                    self.perceived_health = CRITICAL\n",
    "            elif self.health == CRITICAL:\n",
    "                if p < C_prob[NOT_INFECTED]:\n",
    "                    self.perceived_health = NOT_INFECTED\n",
    "                elif p < C_prob[INFECTED_A]:\n",
    "                    self.perceived_health = INFECTED_A\n",
    "                elif p < C_prob[INFECTED_S]:\n",
    "                    self.perceived_health = INFECTED_S\n",
    "                elif p < C_prob[CRITICAL]:\n",
    "                    self.perceived_health = CRITICAL\n",
    "            elif self.health == DECEASED:\n",
    "                self.model.deceasedCount += 1\n",
    "                self.perceived_health = DECEASED\n",
    "                self.reset_death = True\n",
    "                return\n",
    "            \n",
    "            \n",
    "                    \n",
    "        if self.FQ_frames > 0:\n",
    "            self.FQ_frames -= 1\n",
    "        return\n",
    "    \n",
    "    def perceive(self):\n",
    "        x, y = self.pos\n",
    "        return self.model.perceive(x, y, self.unique_id)\n",
    "    \n",
    "    # infect with a probability when interact\n",
    "    def infect(self, close_contact):\n",
    "        p = self.random.uniform(0, 1)\n",
    "        if self.health == NOT_INFECTED:\n",
    "            if close_contact:\n",
    "                self.health += 1\n",
    "                self.infected_times += 1\n",
    "            else:\n",
    "                # disease proceed with different rate\n",
    "                if p < (evolve_prob[NOT_INFECTED] * vaccine_multiplier) and self.vaccinated:\n",
    "                    self.health += 1\n",
    "                    self.infected_times += 1\n",
    "                elif p < evolve_prob[NOT_INFECTED] and not self.vaccinated:\n",
    "                    self.health += 1\n",
    "                    self.infected_times += 1\n",
    "    \n",
    "    def act(self):\n",
    "        x, y = self.pos\n",
    "        \n",
    "        # action selection\n",
    "        self.intention = np.random.choice(intention_space)\n",
    "        \n",
    "        if self.FQ_frames > 0:\n",
    "            self.last_action = MOVE_HOME\n",
    "            if x != HOME:\n",
    "                self.model.grid.move_agent(self, (HOME, self.unique_id // agent_per_home))\n",
    "                self.x = HOME\n",
    "                self.y = self.unique_id // agent_per_home\n",
    "        else:\n",
    "            action = RL_brain.action_select(str(self.state), self.model.iteration, self.evaluate)\n",
    "            # run action\n",
    "            if action == MOVE_HOME:\n",
    "                self.model.grid.move_agent(self, (HOME, self.unique_id // agent_per_home))\n",
    "                self.x = HOME\n",
    "                self.y = self.unique_id // agent_per_home\n",
    "            elif action == MOVE_STORE:\n",
    "                rd = self.random.randint(0, num_grocery_stores - 1)\n",
    "                self.model.grid.move_agent(self, (GROCERY_STORE, rd))\n",
    "                self.x = GROCERY_STORE\n",
    "                self.y = rd\n",
    "            elif action == MOVE_PARK:\n",
    "                rd = self.random.randint(0, num_parks - 1)\n",
    "                self.model.grid.move_agent(self, (PARK, self.random.randint(0, num_parks - 1)))\n",
    "                self.x = PARK\n",
    "                self.y = rd\n",
    "            elif action == MOVE_HOSPITAL:\n",
    "                self.model.grid.move_agent(self, (HOSPITAL, 0))\n",
    "                self.x = HOSPITAL\n",
    "                self.y = 0\n",
    "                self.vaccinated = True\n",
    "                self.vaccine_last = vaccine_last\n",
    " \n",
    "            self.last_action = action\n",
    "\n",
    "        if agent_type in (agent_type_emote, agent_type_hint):\n",
    "            self.elicit_emotion(self.intention)\n",
    "    \n",
    "    # elicit self-directed emotion\n",
    "    def elicit_emotion(self, intention):\n",
    "        x, y = self.pos\n",
    "        \n",
    "        # trigger unpleasant while being forced to stay at home\n",
    "        if x == HOME and self.FQ_frames > 0:\n",
    "            self.self_directed_emotion = -emotion_payoff\n",
    "        # trigger guilty based on norms\n",
    "        else:\n",
    "            emotion = (1 if x == intention else -1)\n",
    "            if x != HOME and self.health > 0:\n",
    "                emotion += -emotion_payoff\n",
    "            elif x == HOME and self.health > 0:\n",
    "                emotion += emotion_payoff\n",
    "    \n",
    "            if emotion > emotion_payoff: emotion = emotion_payoff\n",
    "            if emotion < -emotion_payoff: emotion = -emotion_payoff\n",
    "            self.self_directed_emotion = emotion\n",
    "        \n",
    "\n",
    "    def learn(self, force = False):\n",
    "        x, y = self.pos\n",
    "        pre_state = self.state\n",
    "        \n",
    "        self.reward = 0\n",
    "        env_emotion = 0\n",
    "        \n",
    "        if agent_type in (agent_type_emote, agent_type_hint):\n",
    "            self.state = self.get_state(0)\n",
    "        else:\n",
    "            self.state = self.get_state(0)\n",
    "        \n",
    "        if self.health == DECEASED and not self.reset_death:\n",
    "            if self.x != HOME or self.x != -1:\n",
    "                self.model.grid.move_agent(self, (HOME, self.unique_id // agent_per_home))\n",
    "                self.x = HOME\n",
    "                self.y = self.unique_id // agent_per_home\n",
    "            self.reward, self.FQ_frames = 0, 0\n",
    "            self.self_directed_emotion, self.other_directed_emotion = 0, 0\n",
    "            self.intention, self.last_action, self.x, self.y = -1, -1, -1, -1\n",
    "            return\n",
    "        \n",
    "        reward = -2 if self.health == DECEASED else 0\n",
    "        \n",
    "        if self.FQ_frames > 0:\n",
    "            reward -= 1\n",
    "        \n",
    "        reward += 1 if self.intention == x else -1\n",
    "        \n",
    "        if agent_type in (agent_type_emote, agent_type_hint):\n",
    "            reward += (self.self_directed_emotion + self.other_directed_emotion)\n",
    "        \n",
    "        reward += self.external_reward\n",
    "        \n",
    "        self.reward = reward\n",
    "        \n",
    "        self.reset_death = False\n",
    "        self.external_reward = 0\n",
    "        \n",
    "        if self.evaluate:\n",
    "            return\n",
    "        \n",
    "        RL_brain.learn(str(pre_state), self.last_action, reward, str(self.state))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8fe18820",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimulationModel(Model):\n",
    "    \"\"\"The model runs the simulation.\"\"\"\n",
    "    def __init__(self, N, iteration, evaluate):\n",
    "        self.num_agents = N\n",
    "        self.random.seed(1)\n",
    "        self.evaluate = evaluate\n",
    "        \n",
    "        self.grid = MultiGrid(5, num_agents // agent_per_home, False)\n",
    "        self.schedule = RandomActivation(self)\n",
    "        self.iteration = iteration\n",
    "        \n",
    "        self.deceasedCount = 0\n",
    "        \n",
    "        self.datacollector = DataCollector(\n",
    "            model_reporters={\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        self.reset()\n",
    "    \n",
    "    def reset(self):\n",
    "        if self.schedule.get_agent_count() > 0:\n",
    "            for agent in self.schedule.agents:\n",
    "                self.schedule.remove(agent)\n",
    "        # load agents\n",
    "        for i in range(self.num_agents):\n",
    "            a = HumanAgent(i, self, self.evaluate)\n",
    "            self.schedule.add(a)\n",
    "            self.grid.place_agent(a, (HOME, 0))\n",
    "        \n",
    "        for a in self.random.sample(self.schedule.agents, int(startingState * self.num_agents)):\n",
    "            a.health = INFECTED_A\n",
    "            a.infected_times += 1\n",
    "        \n",
    "        for agent in self.schedule.agents:\n",
    "            agent.initialize()\n",
    "        \n",
    "        self.deceased_count = 0\n",
    "        self.violation_count = 0\n",
    "        self.compliance_count = 0\n",
    "        self.cumulative_deceased = 0\n",
    "        self.cumulative_violation = 0\n",
    "        self.cumulative_compliance = 0\n",
    "    \n",
    "    def run_norms(self):\n",
    "        emotion_saction_set, message_sanction_set, hard_saction_set = set(), set(), set()\n",
    "        # Home\n",
    "        for y in range(num_agents // agent_per_home):\n",
    "            agents = self.grid.get_cell_list_contents([(HOME,y)])\n",
    "            comply_agents = [agent for agent in agents if agent.health != DECEASED and agent.perceived_health != NOT_INFECTED and agent.FQ_frames == 0 ]\n",
    "            for agent in comply_agents:\n",
    "                agent.external_reward -= norm.get(\"consequent\").get(\"hard_sanction\")\n",
    "                if agent_type in (agent_type_hint, agent_type_emote):\n",
    "                    agent.other_directed_emotion = emotion_payoff\n",
    "        # Park\n",
    "        if PARK in norm.get(\"antecedent\").get(\"location\"):\n",
    "            for y in range(num_parks):\n",
    "                agents = self.grid.get_cell_list_contents([(PARK,y)])\n",
    "                agents = [agent for agent in agents if agent.health != DECEASED ]\n",
    "                violate_agents = [agent for agent in agents if getattr(agent, norm.get(\"antecedent\").get(\"attribute\")) in norm.get(\"antecedent\").get(\"value\") ]\n",
    "                \n",
    "                if len(agents) - len(violate_agents) > 0:\n",
    "                    for agent in violate_agents:\n",
    "                        sanctioners = [sanctioner for sanctioner in agents if sanctioner.health == NOT_INFECTED and sanctioner.unique_id != agent.unique_id]    \n",
    "\n",
    "                        hard_sanction, sanction = False, False\n",
    "                        p = self.random.uniform(0, 1)\n",
    "                        if p < sanction_prob_w_health[agent.perceived_health]:\n",
    "                            p = self.random.uniform(0, 1)\n",
    "                            if p < hard_sanctioning_prob:\n",
    "                                agent.FQ_frames = FQ_frames\n",
    "                                hard_sanction = True\n",
    "                            \n",
    "                            elif agent_type == agent_type_message:\n",
    "                                if p < message_sanctioning_prob:\n",
    "                                    sanction = True\n",
    "                                    agent.external_reward += norm.get(\"consequent\").get(\"message\")\n",
    "                            elif agent_type in (agent_type_hint, agent_type_emote):\n",
    "                                if p < emotion_sanctioning_prob:\n",
    "                                    sanction = True\n",
    "                                    if agent_type == agent_type_hint:\n",
    "                                        agent.external_reward += norm.get(\"consequent\").get(\"emotion\")\n",
    "                                    agent.other_directed_emotion = -emotion_payoff\n",
    "\n",
    "                        if agent_type in (agent_type_hint, agent_type_emote) and sanction:\n",
    "                            for sanctioner in sanctioners:\n",
    "                                if sanctioner.unique_id not in emotion_saction_set:\n",
    "                                    emotion_saction_set.add(sanctioner.unique_id)\n",
    "                                    sanctioner.other_directed_emotion = 0\n",
    "\n",
    "        # Grocery\n",
    "        if GROCERY_STORE in norm.get(\"antecedent\").get(\"location\"):\n",
    "            for y in range(num_grocery_stores):\n",
    "                agents = self.grid.get_cell_list_contents([(GROCERY_STORE,y)])\n",
    "                agents = [agent for agent in agents if agent.health != DECEASED ]\n",
    "                violate_agents = [agent for agent in agents if getattr(agent, norm.get(\"antecedent\").get(\"attribute\")) in norm.get(\"antecedent\").get(\"value\") ]\n",
    "                \n",
    "                if len(agents) - len(violate_agents) > 0:\n",
    "                    for agent in violate_agents:\n",
    "                        sanctioners = [sanctioner for sanctioner in agents if sanctioner.health == NOT_INFECTED and sanctioner.unique_id != agent.unique_id]    \n",
    "                        \n",
    "                        hard_sanction, sanction = False, False\n",
    "                        p = self.random.uniform(0, 1)\n",
    "                        if p < sanction_prob_w_health[agent.perceived_health]:\n",
    "                            p = self.random.uniform(0, 1)\n",
    "                            if p < hard_sanctioning_prob:\n",
    "                                agent.FQ_frames = FQ_frames\n",
    "                                hard_sanction = True\n",
    "                            \n",
    "                            elif agent_type == agent_type_message:\n",
    "                                if p < message_sanctioning_prob:\n",
    "                                    sanction = True\n",
    "                                    agent.external_reward += norm.get(\"consequent\").get(\"message\")\n",
    "                            elif agent_type in (agent_type_hint, agent_type_emote):\n",
    "                                if p < emotion_sanctioning_prob:\n",
    "                                    sanction = True\n",
    "                                    if agent_type == agent_type_hint:\n",
    "                                        agent.external_reward += norm.get(\"consequent\").get(\"emotion\")\n",
    "                                    agent.other_directed_emotion = -emotion_payoff\n",
    "\n",
    "                        if agent_type in (agent_type_hint, agent_type_emote) and sanction:\n",
    "                            for sanctioner in sanctioners:\n",
    "                                if sanctioner.unique_id not in emotion_saction_set:\n",
    "                                    emotion_saction_set.add(sanctioner.unique_id)\n",
    "                                    sanctioner.other_directed_emotion = 0\n",
    "\n",
    "            \n",
    "        if HOSPITAL in norm.get(\"antecedent\").get(\"location\"):\n",
    "            agents = self.grid.get_cell_list_contents([(HOSPITAL,0)])\n",
    "            agents = [agent for agent in agents if agent.health != DECEASED ]\n",
    "            violate_agents = [agent for agent in agents if getattr(agent, norm.get(\"antecedent\").get(\"attribute\")) in norm.get(\"antecedent\").get(\"value\") ]\n",
    "            \n",
    "            if len(agents) - len(violate_agents) > 0:\n",
    "                for agent in violate_agents:\n",
    "                    sanctioners = [sanctioner for sanctioner in agents if sanctioner.health == NOT_INFECTED and sanctioner.unique_id != agent.unique_id]\n",
    "                    \n",
    "                    hard_sanction, sanction = False, False\n",
    "                    p = self.random.uniform(0, 1)\n",
    "                    if p < sanction_prob_w_health[agent.perceived_health]:\n",
    "                        p = self.random.uniform(0, 1)\n",
    "                        if p < hard_sanctioning_prob:\n",
    "                            agent.FQ_frames = FQ_frames\n",
    "                            hard_sanction = True\n",
    "                            \n",
    "                        elif agent_type == agent_type_message:\n",
    "                            if p < message_sanctioning_prob:\n",
    "                                sanction = True\n",
    "                                agent.external_reward += norm.get(\"consequent\").get(\"message\")\n",
    "                        elif agent_type in (agent_type_hint, agent_type_emote):\n",
    "                            if p < emotion_sanctioning_prob:\n",
    "                                sanction = True\n",
    "                                if agent_type == agent_type_hint:\n",
    "                                    agent.external_reward += norm.get(\"consequent\").get(\"emotion\")\n",
    "                                agent.other_directed_emotion = -emotion_payoff\n",
    "                \n",
    "                    if agent_type in (agent_type_hint, agent_type_emote) and sanction:\n",
    "                        for sanctioner in sanctioners:\n",
    "                            if sanctioner.unique_id not in emotion_saction_set:\n",
    "                                emotion_saction_set.add(sanctioner.unique_id)\n",
    "                                sanctioner.other_directed_emotion = 0\n",
    "\n",
    "    def perceive(self, x, y, agent_id):\n",
    "        agents = self.grid.get_cell_list_contents([(x, y)])\n",
    "        emotions = [agent.other_directed_emotion for agent in agents if agent.unique_id != agent_id]\n",
    "        return sum(emotions)/len(emotions) if len(emotions) > 0 else 0\n",
    "    \n",
    "    def learn(self):\n",
    "        for i in range(self.num_agents):\n",
    "            agent = self.schedule._agents[i]\n",
    "            agent.learn()\n",
    "    \n",
    "    def compute_infected(self):\n",
    "        infectedAgents = [agent for agent in self.schedule.agents if agent.health in (INFECTED_A, INFECTED_S, CRITICAL) ]\n",
    "        return len(infectedAgents)\n",
    "    \n",
    "    def compute_deceased(self):\n",
    "        deceasedAgents = [agent for agent in self.schedule.agents if agent.health == DECEASED ]\n",
    "        return len(deceasedAgents)\n",
    "    \n",
    "    def compute_compliance(self):\n",
    "        agents = [agent for agent in self.schedule.agents if agent.last_action == MOVE_HOME and agent.health not in (NOT_INFECTED, DECEASED) ]\n",
    "        return len(agents)\n",
    "    \n",
    "    def compute_violation(self):\n",
    "        agents = [agent for agent in self.schedule.agents if agent.last_action != MOVE_HOME and agent.health not in (NOT_INFECTED, DECEASED) ]\n",
    "        return len(agents)\n",
    "    \n",
    "    def compute_compliance_rate(self):\n",
    "        comp = self.compute_compliance()\n",
    "        vio = self.compute_violation()\n",
    "        return comp / (comp + vio) if comp + vio > 0 else 0\n",
    "    \n",
    "    def compute_vaccinated(self):\n",
    "        agents = [agent for agent in self.schedule.agents if agent.vaccinated and agent.health != DECEASED ]\n",
    "        return len(agents)\n",
    "    \n",
    "    def compute_QC(self):\n",
    "        count = 0\n",
    "        for y in range(num_agents // agent_per_home):\n",
    "            agents = self.grid.get_cell_list_contents([(HOME,y)])\n",
    "            count += len(agents)\n",
    "        return count\n",
    "    \n",
    "    def compute_FQ(self):\n",
    "        count = 0\n",
    "        for y in range(num_agents // agent_per_home):\n",
    "            agents = self.grid.get_cell_list_contents([(HOME,y)])\n",
    "            agents = [agent for agent in agents if agent.FQ_frames > 1]\n",
    "            count += len(agents)\n",
    "        return count\n",
    "    \n",
    "    def step(self):\n",
    "        self.schedule.step()\n",
    "        if agent_type != agent_type_primitive:\n",
    "            self.run_norms()\n",
    "        self.identifyAgentsAndUpdateSpread()\n",
    "        self.learn()\n",
    "        self.write_csv()\n",
    "        self.datacollector.collect(self)\n",
    "        self.decay_emotion()\n",
    "    \n",
    "    def decay_emotion(self):\n",
    "        for i in range(self.num_agents):\n",
    "            agent = self.schedule._agents[i]\n",
    "            agent.other_directed_emotion = 0\n",
    "            agent.self_directed_emotion = 0\n",
    "\n",
    "    def write_csv(self):\n",
    "        if self.iteration <= num_train_iterations:\n",
    "            return\n",
    "        \n",
    "        with open(logs_path + file_name + '_agent.csv', 'a', newline = '') as agent_file:\n",
    "            writer = csv.writer(agent_file, delimiter = ',')\n",
    "            for i in range(self.num_agents):\n",
    "                agent = self.schedule._agents[i]\n",
    "                if agent_type in (agent_type_primitive, agent_type_sanctioning):\n",
    "                    writer.writerow([self.iteration, self.schedule.steps, agent.unique_id, agent.health, agent.infected_times, agent.reward, agent.FQ_frames, agent.vaccinated, agent.vaccine_last, agent.intention, agent.last_action, agent.x, agent.y, agent.self_directed_emotion, agent.other_directed_emotion])\n",
    "                elif agent_type == agent_type_message:\n",
    "                    writer.writerow([self.iteration, self.schedule.steps, agent.unique_id, agent.health, agent.infected_times, agent.reward, agent.FQ_frames, agent.vaccinated, agent.vaccine_last, agent.intention, agent.last_action, agent.x, agent.y, agent.self_directed_emotion, agent.other_directed_emotion])\n",
    "                elif agent_type == agent_type_emote:\n",
    "                    writer.writerow([self.iteration, self.schedule.steps, agent.unique_id, agent.health, agent.infected_times, agent.reward, agent.FQ_frames, agent.vaccinated, agent.vaccine_last, agent.intention, agent.last_action, agent.x, agent.y, agent.self_directed_emotion, agent.other_directed_emotion])\n",
    "                else:\n",
    "                    writer.writerow([self.iteration, self.schedule.steps, agent.unique_id, agent.health, agent.infected_times, agent.reward, agent.FQ_frames, agent.vaccinated, agent.vaccine_last, agent.intention, agent.last_action, agent.x, agent.y, agent.self_directed_emotion, agent.other_directed_emotion])\n",
    "        agent_file.close()\n",
    "    \n",
    "    def identifyAgentsAndUpdateSpread(self):\n",
    "        # Park\n",
    "        for y in range(num_parks):\n",
    "            agents = self.grid.get_cell_list_contents([(PARK,y)])\n",
    "            self.updateSpread(agents)\n",
    "        # Grocery\n",
    "        for y in range(num_grocery_stores):\n",
    "            agents = self.grid.get_cell_list_contents([(GROCERY_STORE,y)])\n",
    "            self.updateSpread(agents)\n",
    "        # Home\n",
    "        for y in range(num_agents // agent_per_home):\n",
    "            agents = self.grid.get_cell_list_contents([(HOME,y)])\n",
    "            self.updateSpread(agents, True)\n",
    "    def updateSpread(self, agents, close_contact = False):\n",
    "        if any(a.health in (INFECTED_A, INFECTED_S, CRITICAL) for a in agents):\n",
    "            [a.infect(close_contact) for a in agents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "60c38d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_simulation(iteration, evaluate):\n",
    "    model = SimulationModel(num_agents, iteration, evaluate)\n",
    "    for i in range(num_steps):\n",
    "        model.step()\n",
    "    modelDF = model.datacollector.get_model_vars_dataframe()\n",
    "    return model.deceasedCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "30f9cedb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|█▏                                                                                 | 1/70 [00:49<57:15, 49.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|██▎                                                                                | 2/70 [01:36<54:11, 47.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|███▌                                                                               | 3/70 [02:27<54:55, 49.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|████▋                                                                              | 4/70 [03:12<52:41, 47.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|█████▉                                                                             | 5/70 [03:59<51:20, 47.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  9%|███████                                                                            | 6/70 [04:50<52:00, 48.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|████████▎                                                                          | 7/70 [05:42<52:08, 49.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 11%|█████████▍                                                                         | 8/70 [06:39<53:39, 51.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 13%|██████████▋                                                                        | 9/70 [07:34<53:49, 52.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 14%|███████████▋                                                                      | 10/70 [08:33<54:43, 54.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|████████████▉                                                                     | 11/70 [09:32<55:07, 56.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|██████████████                                                                    | 12/70 [10:32<55:27, 57.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 19%|███████████████▏                                                                  | 13/70 [11:32<55:20, 58.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|████████████████▍                                                                 | 14/70 [12:35<55:28, 59.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 21%|█████████████████▌                                                                | 15/70 [13:36<55:03, 60.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 23%|██████████████████▋                                                               | 16/70 [14:44<56:08, 62.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|███████████████████▉                                                              | 17/70 [15:46<54:56, 62.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 26%|█████████████████████                                                             | 18/70 [16:51<54:48, 63.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 27%|██████████████████████▎                                                           | 19/70 [18:03<55:50, 65.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 29%|███████████████████████▍                                                          | 20/70 [19:06<54:14, 65.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|████████████████████████▌                                                         | 21/70 [20:14<53:52, 65.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 31%|█████████████████████████▊                                                        | 22/70 [21:26<54:13, 67.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|██████████████████████████▉                                                       | 23/70 [22:44<55:29, 70.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 34%|████████████████████████████                                                      | 24/70 [23:55<54:21, 70.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 36%|█████████████████████████████▎                                                    | 25/70 [25:07<53:26, 71.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 37%|██████████████████████████████▍                                                   | 26/70 [26:21<52:46, 71.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 39%|███████████████████████████████▋                                                  | 27/70 [27:42<53:30, 74.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████████████████████████████████▊                                                 | 28/70 [29:05<53:59, 77.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 41%|█████████████████████████████████▉                                                | 29/70 [30:25<53:23, 78.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 43%|███████████████████████████████████▏                                              | 30/70 [31:49<53:16, 79.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 44%|████████████████████████████████████▎                                             | 31/70 [33:27<55:18, 85.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 46%|█████████████████████████████████████▍                                            | 32/70 [34:53<54:14, 85.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 47%|██████████████████████████████████████▋                                           | 33/70 [36:26<54:07, 87.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 49%|███████████████████████████████████████▊                                          | 34/70 [38:02<54:02, 90.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████████████████████████████████████████                                         | 35/70 [39:33<52:46, 90.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 51%|██████████████████████████████████████████▏                                       | 36/70 [41:16<53:20, 94.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 53%|███████████████████████████████████████████▎                                      | 37/70 [43:02<53:46, 97.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 54%|███████████████████████████████████████████▉                                     | 38/70 [44:51<53:52, 101.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 56%|█████████████████████████████████████████████▏                                   | 39/70 [46:34<52:36, 101.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 57%|██████████████████████████████████████████████▎                                  | 40/70 [48:43<55:00, 110.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 59%|███████████████████████████████████████████████▍                                 | 41/70 [50:59<56:51, 117.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|████████████████████████████████████████████████▌                                | 42/70 [53:08<56:28, 121.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 61%|█████████████████████████████████████████████████▊                               | 43/70 [55:21<56:06, 124.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 63%|██████████████████████████████████████████████████▉                              | 44/70 [57:34<55:10, 127.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 64%|████████████████████████████████████████████████████                             | 45/70 [59:52<54:22, 130.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 66%|███████████████████████████████████████████████████▉                           | 46/70 [1:02:04<52:17, 130.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|█████████████████████████████████████████████████████                          | 47/70 [1:04:14<50:04, 130.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 69%|██████████████████████████████████████████████████████▏                        | 48/70 [1:06:26<48:01, 130.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|███████████████████████████████████████████████████████▎                       | 49/70 [1:08:47<46:56, 134.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 71%|████████████████████████████████████████████████████████▍                      | 50/70 [1:11:08<45:20, 136.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 73%|█████████████████████████████████████████████████████████▌                     | 51/70 [1:12:28<37:47, 119.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 74%|██████████████████████████████████████████████████████████▋                    | 52/70 [1:13:47<32:10, 107.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 76%|███████████████████████████████████████████████████████████▊                   | 53/70 [1:15:16<28:47, 101.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 77%|█████████████████████████████████████████████████████████████▋                  | 54/70 [1:16:44<26:00, 97.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 79%|██████████████████████████████████████████████████████████████▊                 | 55/70 [1:18:03<23:00, 92.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████████████████████████████████████████████████████████████                | 56/70 [1:19:03<19:12, 82.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 81%|█████████████████████████████████████████████████████████████████▏              | 57/70 [1:20:21<17:34, 81.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 83%|██████████████████████████████████████████████████████████████████▎             | 58/70 [1:21:31<15:32, 77.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 84%|███████████████████████████████████████████████████████████████████▍            | 59/70 [1:22:43<13:56, 76.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 86%|████████████████████████████████████████████████████████████████████▌           | 60/70 [1:24:11<13:17, 79.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 87%|█████████████████████████████████████████████████████████████████████▋          | 61/70 [1:25:26<11:45, 78.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 89%|██████████████████████████████████████████████████████████████████████▊         | 62/70 [1:26:30<09:52, 74.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|████████████████████████████████████████████████████████████████████████        | 63/70 [1:28:00<09:10, 78.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 91%|█████████████████████████████████████████████████████████████████████████▏      | 64/70 [1:29:10<07:36, 76.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 93%|██████████████████████████████████████████████████████████████████████████▎     | 65/70 [1:30:18<06:08, 73.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 94%|███████████████████████████████████████████████████████████████████████████▍    | 66/70 [1:31:38<05:02, 75.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 96%|████████████████████████████████████████████████████████████████████████████▌   | 67/70 [1:33:13<04:04, 81.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 97%|█████████████████████████████████████████████████████████████████████████████▋  | 68/70 [1:34:17<02:32, 76.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 99%|██████████████████████████████████████████████████████████████████████████████▊ | 69/70 [1:35:38<01:17, 77.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 70/70 [1:36:48<00:00, 82.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deceasedCount 27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "infected, deceased, quarantine, compliance, violation, ratio, vaccinated = None, None, None, None, None, None, None\n",
    "for i in tqdm(range(1, num_train_iterations + num_eval_iterations + 1)):\n",
    "    deceasedCount = run_simulation(i, True if i > num_train_iterations else False)\n",
    "    print('deceasedCount', deceasedCount)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "be7a1cb9",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu",
   "language": "python",
   "name": "noe"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
